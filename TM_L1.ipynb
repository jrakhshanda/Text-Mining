{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TM_L1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrakhshanda/Text-Mining/blob/main/TM_L1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyClHxwm0WYE"
      },
      "source": [
        "# L1: Information retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QEUdO7K0WYF"
      },
      "source": [
        "In this lab you will apply basic techniques from information retrieval to implement the core of a minimalistic search engine. The data for this lab consists of a collection of app descriptions scraped from the [Google Play Store](https://play.google.com/store/apps?hl=en). From this collection, your search engine should retrieve those apps whose descriptions best match a given query under the vector space model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyQFwWof0WYG"
      },
      "source": [
        "## Data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJAgio500WYG"
      },
      "source": [
        "The app descriptions come in the form of a compressed [JSON](https://en.wikipedia.org/wiki/JSON) file. Start by loading this file into a [Pandas](https://pandas.pydata.org) [DataFrame](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html#dataframe)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjhKviht0WYH"
      },
      "source": [
        "import bz2\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "with bz2.open('app-descriptions.json.bz2') as source:\n",
        "    df = pd.read_json(source)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW2sC6Ak0WYN"
      },
      "source": [
        "In Pandas, a DataFrame is a table with indexed rows and labelled columns of potentially different types. Data in a DataFrame can be accessed in various ways, including by row and by column. To give an example, the code in the next cell shows rows 200–204:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdID8d2J0WYO",
        "outputId": "9651de62-95d5-4b49-83be-3a085133e5dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "df[200:205]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>Brick Breaker Star: Space King</td>\n",
              "      <td>Introducing the best Brick Breaker game that e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>Brick Classic - Brick Game</td>\n",
              "      <td>Classic Brick Game!\\n\\nBrick Classic is a popu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>Bricks Breaker - Glow Balls</td>\n",
              "      <td>Bricks Breaker - Glow Balls is a addictive and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>Bricks Breaker Quest</td>\n",
              "      <td>How to play\\n- The ball flies to wherever you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>Brothers in Arms® 3</td>\n",
              "      <td>Fight brave soldiers from around the globe on ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               name                                        description\n",
              "200  Brick Breaker Star: Space King  Introducing the best Brick Breaker game that e...\n",
              "201      Brick Classic - Brick Game  Classic Brick Game!\\n\\nBrick Classic is a popu...\n",
              "202     Bricks Breaker - Glow Balls  Bricks Breaker - Glow Balls is a addictive and...\n",
              "203            Bricks Breaker Quest  How to play\\n- The ball flies to wherever you ...\n",
              "204             Brothers in Arms® 3  Fight brave soldiers from around the globe on ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71oQIsqX0WYT"
      },
      "source": [
        "As you can see, there are two labelled columns: `name` (the name of the app) and `description` (a textual description). The code in the next cell shows how to acess fields from the description column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdR2hLWZ0WYU",
        "outputId": "6ed5ee3b-fb7d-4251-d5e3-28f14f4ab9c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['description'][200:205]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200    Introducing the best Brick Breaker game that e...\n",
              "201    Classic Brick Game!\\n\\nBrick Classic is a popu...\n",
              "202    Bricks Breaker - Glow Balls is a addictive and...\n",
              "203    How to play\\n- The ball flies to wherever you ...\n",
              "204    Fight brave soldiers from around the globe on ...\n",
              "Name: description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJq-KjKV0WYW"
      },
      "source": [
        "## Problem 1: Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuuSHOe00WYX"
      },
      "source": [
        "Your first task is to implement a preprocessor for your search engine. In the vector space model, *preprocessing* refers to any kind of transformation that is applied before a text is vectorized. Here you can restrict yourself to a very simple preprocessing: tokenization, stop word removal, and lemmatization.\n",
        "\n",
        "To implement your preprocessor, you can use [spaCy](https://spacy.io). Make sure that you read the [Linguistic annotations](https://spacy.io/usage/spacy-101#annotations) section of the spaCy&nbsp;101; that section contains all the information that you need for this problem (and more).\n",
        "\n",
        "Implement your preprocessor by completing the skeleton code in the next cell, adding additional code as you feel necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9in8JaAQ0WYY"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\",\"entityrecognizer\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sbr38_G1f1T"
      },
      "source": [
        "def preprocess(text):\n",
        "  doc = nlp(text)\n",
        "  res = []\n",
        "  for token in doc:\n",
        "    if not token.is_stop:\n",
        "      if token.is_alpha:\n",
        "        res.append(token.lemma_)\n",
        "  return (res)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHSn8nhn0WYa"
      },
      "source": [
        "Your implementation should conform to the following specification:\n",
        "\n",
        "<strong>preprocess</strong> (<em>text</em>)\n",
        "\n",
        "> Preprocesses given text by tokenizing it, removing any stop words, replacing each remaining token with its lemma (base form), and discarding all lemmas that contain non-alphabetical characters. Returns the list of remaining lemmas (represented as strings).\n",
        "\n",
        "**Tip:** To speed up the preprocessing, you can disable loading those spaCy components that you do not need, such as the part-of-speech tagger, parser, and named entity recognizer. See [here](https://spacy.io/usage/processing-pipelines#disabling) for more information about this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpL4C0aC0WYb"
      },
      "source": [
        "Test your implementation by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7oDuela0WYb",
        "outputId": "3bbaae27-b740-4c27-fc00-7735e3ff96cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "preprocess('Apple is looking at buying U.K. startup for $1 billion')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Apple', 'look', 'buy', 'startup', 'billion']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iLVoOzI0WYf"
      },
      "source": [
        "This should give the following output:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSlvTey-0WYf"
      },
      "source": [
        "['Apple', 'look', 'buy', 'startup', 'billion']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnyCsqxY0WYg"
      },
      "source": [
        "## Problem 2: Vectorizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yumkyNR0WYg"
      },
      "source": [
        "Your next task is to vectorize the data – and more specifically, to map each app description to a tf–idf vector. For this you can use the [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class from [scikit-learn](https://scikit-learn.org/stable/). Make sure to specify your preprocessor from the previous problem as the `tokenizer` &ndash; not the `preprocessor`! &ndash; for the vectorizer. (In scikit-learn parlance, the `preprocessor` handles string-level preprocessing.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g0b10zv0WYi"
      },
      "source": [
        "import numpy as np\n",
        "# TODO: Replace the next line with your own code.\n",
        "#X = np.zeros((len(df), 1))\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#corpus = [preprocess(i) for i in df['description']]\n",
        "vectorizer = TfidfVectorizer(tokenizer = preprocess)\n",
        "X = vectorizer.fit_transform( df['description'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "709Rdo0t0WYl"
      },
      "source": [
        "Test your implementation by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b16bwUeX0WYm",
        "outputId": "8b47acd6-d426-43d3-9d0b-460391db5d36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1614, 20663)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4-abLQ-0WYp"
      },
      "source": [
        "This should show the dimensions of the matrix `X` to be 1614 × 20669."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkgnWO0v0WYp"
      },
      "source": [
        "## Problem 3: Retrieving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRUmB3Qk0WYq"
      },
      "source": [
        "To complete the search engine, your last task is to write a function that returns the most relevant app descriptions for a given query. An easy way to do solve this task is to use scikit-learn&rsquo;s [NearestNeighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html) class. That class implements unsupervised nearest neighbours learning, and allows you to easily find a predefined number of app descriptions whose vector representations are closest to the query vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6RtxR9opiRC",
        "outputId": "743b3743-6a04-48ad-e932-52135009f49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "query = 'dodge trains'\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics.pairwise import cosine_distances,cosine_similarity\n",
        "preprocess(query)\n",
        "model = NearestNeighbors(n_neighbors=10, metric=cosine_similarity).fit(X)\n",
        "test = vectorizer.fit_transform([query]).reshape(-1,1)\n",
        "model.kneighbors(test,return_distance=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-28b7f4d42323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 **kwds))\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ball_tree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kd_tree'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1593\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0;32m-> 1595\u001b[0;31m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[1;32m   1596\u001b[0m         if ((X is Y or Y is None)\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \"\"\"Handle the callable case for pairwise_{distances,kernels}\n\u001b[1;32m   1367\u001b[0m     \"\"\"\n\u001b[0;32m-> 1368\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    153\u001b[0m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[1;32m    154\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[0;32m--> 155\u001b[0;31m                              X.shape[1], Y.shape[1]))\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 1 while Y.shape[1] == 20663"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAGl-pglxmpM"
      },
      "source": [
        "query = 'dodge trains'\n",
        "preprocess(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrFuD1ui0WYr"
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "model = NearestNeighbors()\n",
        "def search(query):\n",
        "  model = NearestNeighbors()\n",
        "    # TODO: Replace the next line with your own code.\n",
        "    return df.iloc[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trlo1dg80WYt"
      },
      "source": [
        "Your implementation should conform to the following specification:\n",
        "\n",
        "<strong>search</strong> (<em>query</em>)\n",
        "\n",
        "> Returns the 10 app descriptions most similar (in terms of cosine similarity) to the given query as a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrrw4YLT0WYu"
      },
      "source": [
        "Test your implementation by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bswUccXJ0WYu"
      },
      "source": [
        "search('dodge trains')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNS7WLK-0WYx"
      },
      "source": [
        "The top hit in the list should be *Subway Surfers*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGH9udaP0WYy"
      },
      "source": [
        "## Problem 4: Finding terms with low/high idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLmeVRdQ0WYz"
      },
      "source": [
        "Recall that the inverse document frequency (idf) of a term is the lower the more documents from a given collection the term appears in. To get a better understanding for this concept, your next task is to write code to find out which terms have the lowest/highest idf with respect to the app descriptions.\n",
        "\n",
        "Start by sorting the terms in increasing order of idf, breaking ties by falling back on alphabetic order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGjZaZkw0WYz"
      },
      "source": [
        "# TODO: Replace the next line with your own code.\n",
        "terms = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okp5mo_j0WY2"
      },
      "source": [
        "Now, print the 10 terms with the lowest/highest idf. How do you explain the results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lZIDZuGP0WY2"
      },
      "source": [
        "print(terms[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJSc8NF-0WY5"
      },
      "source": [
        "*TODO: Enter your explanation here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR7Tgt6R0WY6"
      },
      "source": [
        "## Problem 5: Keyword extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzLBgugr0WY6"
      },
      "source": [
        "A simple method for extracting salient keywords from a document is to pick the $k$ terms with the highest tf–idf value. Your last task in this lab is to implement this method. More specifically, we ask you to implement a function `keywords` that extracts keywords from a given text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4oX9XMK0WY7"
      },
      "source": [
        "def keywords(text, n=10):\n",
        "    # TODO: Replace the next line with your own code.\n",
        "    return []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw4lGY9N0WY9"
      },
      "source": [
        "Your implementation should conform to the following specification:\n",
        "\n",
        "<strong>keywords</strong> (<em>text</em>, <em>n</em> = 10)\n",
        "\n",
        "> Returns a list with the $n$ (default value: 10) most salient keywords from the specified text, as measured by their tf–idf value relative to the collection of app descriptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgLVHMSJ0WY-"
      },
      "source": [
        "Test your implementation by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asDtbobw0WY_"
      },
      "source": [
        "print(keywords(df['description'][1428]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7kDsOQu0WZD"
      },
      "source": [
        "This should give the following output:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwE3bJku0WZE"
      },
      "source": [
        "['train', 'railway', 'railroad', 'rail', 'chaos', 'crash', 'overcast', 'locomotive', 'timetable', 'railyard']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg-XOtlG0WZF"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    Please read the General information section on the lab web page before submitting this notebook!\n",
        "</div>"
      ]
    }
  ]
}