{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "word-counts_approach.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrakhshanda/Text-Mining/blob/main/Text_mining_report/word_counts_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSyIcK775hZe"
      },
      "source": [
        "### This is a simple solution using only word counts with CountVectorizer to make predictions.\n",
        "\n",
        "#### Here's the idea:\n",
        "- Find and weight words that are used most often in only certain kinds of tweets.\n",
        "- Search all subsets of the tweet and calculate a score based on these weights.\n",
        "- For positive or negative tweets, the selected text is the most highly weighted subset, within some threshold.\n",
        "- Always return the entire text for neutral tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0FwIwtP6ffM",
        "outputId": "ab997f00-433a-459e-aa6b-185ee40bfd34"
      },
      "source": [
        "import re\r\n",
        "import string\r\n",
        "import numpy as np \r\n",
        "import random\r\n",
        "import pandas as pd \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "from plotly import graph_objs as go\r\n",
        "import plotly.express as px\r\n",
        "import plotly.figure_factory as ff\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "import os\r\n",
        "from sklearn import model_selection, metrics\r\n",
        "import nltk\r\n",
        "import spacy\r\n",
        "import random\r\n",
        "from spacy.util import compounding\r\n",
        "from spacy.util import minibatch\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "from sklearn import model_selection\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "import os\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPe6FgX56PXQ",
        "outputId": "425b547c-4074-4222-ca22-a5a9f1c5ab1e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6Oa2iTlA5hZh"
      },
      "source": [
        "# Import datasets\n",
        "df = pd.read_csv('/content/drive/MyDrive/train.csv', keep_default_na=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "XW7C-MR-5hZh",
        "outputId": "731b4393-9f0e-4aef-d24c-44e2c618e44c"
      },
      "source": [
        "train[train['text'].isna()]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [textID, text, selected_text, sentiment]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7K3f4QX5hZi"
      },
      "source": [
        "Break up the training data into datasets where the sentiment is positive, neutral, or negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4DdrSKWz5hZj"
      },
      "source": [
        "# Make all the text lowercase - casing doesn't matter when \n",
        "# we choose our selected text.\n",
        "train['text'] = train['text'].apply(lambda x: x.lower())\n",
        "\n",
        "# Make training/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val = train_test_split(\n",
        "    train, train_size = 0.80, random_state = 0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eCCWY1Tm5hZj"
      },
      "source": [
        "pos_train = X_train[X_train['sentiment'] == 'positive']\n",
        "neutral_train = X_train[X_train['sentiment'] == 'neutral']\n",
        "neg_train = X_train[X_train['sentiment'] == 'negative']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaGhtgzd5hZj"
      },
      "source": [
        "### Algorithm for weight calculation:\n",
        "\n",
        "1. For each class $j \\in \\{positive, neutral, negative\\}$\n",
        "\n",
        "    a. Find all the words $i$ in the tweets belonging to class $j$.\n",
        "\n",
        "    b. Calculate $n_{i, j} =$ the number of tweets in class $j$ containing word $i$. \n",
        "\n",
        "    c. Let $d_j$ be the number of tweets in class $j$.  Calculate $p_{i, j} = \\frac{n_{i, j}}{d_j}$, the proportion of tweets in class $j$ that conain word $i$.\n",
        "\n",
        "    d. Let $w_{i, j} = p_{i, j} - \\sum\\limits_{k \\neq j}p_{i, k}$ be the weights assigned to each word within each class. \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LQ5-kh8U5hZk"
      },
      "source": [
        "# Use CountVectorizer to get the word counts within each dataset\n",
        "\n",
        "cv = CountVectorizer(max_df=0.95, min_df=2,\n",
        "                                     max_features=10000,\n",
        "                                     stop_words='english')\n",
        "\n",
        "X_train_cv = cv.fit_transform(X_train['text'])\n",
        "\n",
        "X_pos = cv.transform(pos_train['text'])\n",
        "X_neutral = cv.transform(neutral_train['text'])\n",
        "X_neg = cv.transform(neg_train['text'])\n",
        "\n",
        "pos_count_df = pd.DataFrame(X_pos.toarray(), columns=cv.get_feature_names())\n",
        "neutral_count_df = pd.DataFrame(X_neutral.toarray(), columns=cv.get_feature_names())\n",
        "neg_count_df = pd.DataFrame(X_neg.toarray(), columns=cv.get_feature_names())\n",
        "\n",
        "# Create dictionaries of the words within each sentiment group, where the values are the proportions of tweets that \n",
        "# contain those words\n",
        "\n",
        "pos_words = {}\n",
        "neutral_words = {}\n",
        "neg_words = {}\n",
        "\n",
        "for k in cv.get_feature_names():\n",
        "    pos = pos_count_df[k].sum()\n",
        "    neutral = neutral_count_df[k].sum()\n",
        "    neg = neg_count_df[k].sum()\n",
        "    \n",
        "    pos_words[k] = pos/pos_train.shape[0]\n",
        "    neutral_words[k] = neutral/neutral_train.shape[0]\n",
        "    neg_words[k] = neg/neg_train.shape[0]\n",
        "    \n",
        "# We need to account for the fact that there will be a lot of words used in tweets of every sentiment.  \n",
        "# Therefore, we reassign the values in the dictionary by subtracting the proportion of tweets in the other \n",
        "# sentiments that use that word.\n",
        "\n",
        "neg_words_adj = {}\n",
        "pos_words_adj = {}\n",
        "neutral_words_adj = {}\n",
        "\n",
        "for key, value in neg_words.items():\n",
        "    neg_words_adj[key] = neg_words[key] - (neutral_words[key] + pos_words[key])\n",
        "    \n",
        "for key, value in pos_words.items():\n",
        "    pos_words_adj[key] = pos_words[key] - (neutral_words[key] + neg_words[key])\n",
        "    \n",
        "for key, value in neutral_words.items():\n",
        "    neutral_words_adj[key] = neutral_words[key] - (neg_words[key] + pos_words[key])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-mZeT_K5hZk"
      },
      "source": [
        "### Algorithm for finding selected text: \n",
        "  \n",
        "1. For every tweet:\n",
        "\n",
        "    a. Let $j$ be the sentiment of the tweet. \n",
        "\n",
        "    b. If $j ==$ neutral return entire text.\n",
        "\n",
        "    c. Otherwise, for each subset of words in the tweet, calculate $\\sum\\limits_{i}w_{i, j}$, where $i$ is the set of words in the tweet\n",
        "\n",
        "   d. Return the subset of words with the largest sum, given that it exceeds some tolerance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3ITHvHgW5hZl"
      },
      "source": [
        "def calculate_selected_text(df_row, tol = 0):\n",
        "    \n",
        "    tweet = df_row['text']\n",
        "    sentiment = df_row['sentiment']\n",
        "    \n",
        "    if(sentiment == 'neutral'):\n",
        "        return tweet\n",
        "    \n",
        "    elif(sentiment == 'positive'):\n",
        "        dict_to_use = pos_words_adj # Calculate word weights using the pos_words dictionary\n",
        "    elif(sentiment == 'negative'):\n",
        "        dict_to_use = neg_words_adj # Calculate word weights using the neg_words dictionary\n",
        "        \n",
        "    words = tweet.split()\n",
        "    words_len = len(words)\n",
        "    subsets = [words[i:j+1] for i in range(words_len) for j in range(i,words_len)]\n",
        "    \n",
        "    score = 0\n",
        "    selection_str = '' # This will be our choice\n",
        "    lst = sorted(subsets, key = len) # Sort candidates by length\n",
        "    \n",
        "    \n",
        "    for i in range(len(subsets)):\n",
        "        \n",
        "        new_sum = 0 # Sum for the current substring\n",
        "        \n",
        "        # Calculate the sum of weights for each word in the substring\n",
        "        for p in range(len(lst[i])):\n",
        "            if(lst[i][p].translate(str.maketrans('','',string.punctuation)) in dict_to_use.keys()):\n",
        "                new_sum += dict_to_use[lst[i][p].translate(str.maketrans('','',string.punctuation))]\n",
        "            \n",
        "        # If the sum is greater than the score, update our current selection\n",
        "        if(new_sum > score + tol):\n",
        "            score = new_sum\n",
        "            selection_str = lst[i]\n",
        "            #tol = tol*5 # Increase the tolerance a bit each time we choose a selection\n",
        "\n",
        "    # If we didn't find good substrings, return the whole text\n",
        "    if(len(selection_str) == 0):\n",
        "        selection_str = words\n",
        "        \n",
        "    return ' '.join(selection_str)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtOpyiK-5hZl"
      },
      "source": [
        "Calculate the selected text and score for the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HR2jB9UQ5hZm"
      },
      "source": [
        "pd.options.mode.chained_assignment = None"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JszFxbmS5hZm"
      },
      "source": [
        "tol = 0.001\n",
        "\n",
        "X_val['predicted_selection'] = ''\n",
        "\n",
        "for index, row in X_val.iterrows():\n",
        "    \n",
        "    selected_text = calculate_selected_text(row, tol)\n",
        "    \n",
        "    X_val.loc[X_val['textID'] == row['textID'], ['predicted_selection']] = selected_text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "5La7pGkO9S-Z",
        "outputId": "a16f11fa-6e33-478c-ec92-2bb601d016c1"
      },
      "source": [
        "X_val.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>predicted_selection</th>\n",
              "      <th>jaccard</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8243</th>\n",
              "      <td>0565c06b55</td>\n",
              "      <td>glad you are having a blast.</td>\n",
              "      <td>Glad</td>\n",
              "      <td>positive</td>\n",
              "      <td>glad</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12902</th>\n",
              "      <td>93d46ca978</td>\n",
              "      <td>when you haven`t had one in over a week! that...</td>\n",
              "      <td>mean</td>\n",
              "      <td>negative</td>\n",
              "      <td>when you haven`t had one in over a week! that ...</td>\n",
              "      <td>0.052632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6708</th>\n",
              "      <td>1f30caf2c0</td>\n",
              "      <td>thanks  glad you like it</td>\n",
              "      <td>thanks</td>\n",
              "      <td>positive</td>\n",
              "      <td>thanks glad</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26898</th>\n",
              "      <td>2f72905dbd</td>\n",
              "      <td>its 1:11am and both my girls are still up! .. ...</td>\n",
              "      <td>im so tired</td>\n",
              "      <td>negative</td>\n",
              "      <td>tired</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20706</th>\n",
              "      <td>bd0450f89b</td>\n",
              "      <td>my skin is burning up so much</td>\n",
              "      <td>burning</td>\n",
              "      <td>negative</td>\n",
              "      <td>my skin is burning up so much</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           textID  ...   jaccard\n",
              "8243   0565c06b55  ...  1.000000\n",
              "12902  93d46ca978  ...  0.052632\n",
              "6708   1f30caf2c0  ...  0.500000\n",
              "26898  2f72905dbd  ...  0.333333\n",
              "20706  bd0450f89b  ...  0.142857\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o3Z5DQqo5hZm"
      },
      "source": [
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOusr0mZ5hZm",
        "outputId": "d684c467-f577-461f-938b-6896d4495369"
      },
      "source": [
        "X_val['jaccard'] = X_val.apply(lambda x: jaccard(x['selected_text'], x['predicted_selection']), axis = 1)\n",
        "\n",
        "print('The jaccard score for the validation set is:', np.mean(X_val['jaccard']))\n",
        "jaccs = np.mean(X_val['jaccard'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The jaccard score for the validation set is: 0.651373471729071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGRjU3W88RPW"
      },
      "source": [
        "def evaluation_report(gold, pred):\r\n",
        "    \"\"\"Print precision, recall, and F1 score.\r\n",
        "    \r\n",
        "    Args:\r\n",
        "        gold: The set with the gold-standard values.\r\n",
        "        pred: The set with the predicted values.\r\n",
        "    \r\n",
        "    Returns:\r\n",
        "        Nothing, but prints the precision, recall, and F1 values computed\r\n",
        "        based on the specified sets.\r\n",
        "    \"\"\"\r\n",
        "    gold = set(gold)\r\n",
        "    pred = set(pred)\r\n",
        "    # TODO: Replace the next line with your own code\r\n",
        "    precision = len(gold.intersection(pred))/len(pred)\r\n",
        "    recall = len(gold.intersection(pred))/len(gold)\r\n",
        "    F1_score = 2 * (precision*recall) / (precision + recall)\r\n",
        "    df = pd.DataFrame(data=[{'precision': precision, 'recall':recall, 'F1_score':F1_score, 'jaccard_similarity': jaccs}]) \r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "-x_Jy8rS9E4u",
        "outputId": "a53e096b-2d68-4288-d7a5-a877615f94f6"
      },
      "source": [
        "evaluation_report(str(X_val['selected_text']),str(X_val['predicted_selection']))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>F1_score</th>\n",
              "      <th>jaccard_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.930233</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.651373</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision    recall  F1_score  jaccard_similarity\n",
              "0   0.930233  0.888889  0.909091            0.651373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABUatP8H9dGz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}