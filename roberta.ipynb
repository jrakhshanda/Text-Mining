{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roberta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPHr6WnBVGm+szbFnJBOPju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f551f8206e334cad9109367e0ace3b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_36180703c37642bbb38497e863dbc4dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_421a1536479f4604b365f62cce607c74",
              "IPY_MODEL_59b422066ec24a0a8e2296e50b27a260"
            ]
          }
        },
        "36180703c37642bbb38497e863dbc4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "421a1536479f4604b365f62cce607c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_926b0d72691e407d9fd59b551a409649",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0443a4c4aef49e087bef65a49c7d380"
          }
        },
        "59b422066ec24a0a8e2296e50b27a260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15b03a41dff44005b6af00232513aa99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 18.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd866624b374476eb1d5d40267adffb0"
          }
        },
        "926b0d72691e407d9fd59b551a409649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0443a4c4aef49e087bef65a49c7d380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15b03a41dff44005b6af00232513aa99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd866624b374476eb1d5d40267adffb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d865d0a54e04f8eb1d72af61423ea03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ef9cc20681f4444aa7ab854f67c3afcc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_098ff8cb520e45c3935ced30603ea183",
              "IPY_MODEL_399fac77b6464323a715ba1f39d58690"
            ]
          }
        },
        "ef9cc20681f4444aa7ab854f67c3afcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "098ff8cb520e45c3935ced30603ea183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9aa7eca8010f4c0d815a20086f7b306a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_042949d18d8a4e868c466466e118915e"
          }
        },
        "399fac77b6464323a715ba1f39d58690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb112d357a10455fad2d29d8bf7bef86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:06&lt;00:00, 72.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35643256d93e41fe9e79617b9aa03368"
          }
        },
        "9aa7eca8010f4c0d815a20086f7b306a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "042949d18d8a4e868c466466e118915e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb112d357a10455fad2d29d8bf7bef86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35643256d93e41fe9e79617b9aa03368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrakhshanda/Text-Mining/blob/main/roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekcMUspsNFY2",
        "outputId": "4e576beb-0d3c-4d39-c1da-2bc9df676e7c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVGoYWYBP9gs"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install tokenizers\r\n",
        "#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\r\n",
        "#!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\r\n",
        "#!export XLA_USE_BF16=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDDlFXNGvhtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d48465c-840f-44c6-bb69-ae33e3efad5f"
      },
      "source": [
        "#df, test = model_selection.train_test_split(df_train,test_size=0.1)\r\n",
        "#test.to_csv('/content/drive/MyDrive/BERT_files/test_fold.csv')\r\n",
        "\r\n",
        "#df[\"kfold\"] = -1\r\n",
        "#df = df.sample(frac=1).reset_index(drop=True)\r\n",
        "\r\n",
        "#kf = model_selection.StratifiedKFold(n_splits=5)\r\n",
        "\r\n",
        "#for fold, (trn_, val_) in enumerate(kf.split(X=df, y=df.sentiment.values)):\r\n",
        "#    print(len(trn_), len(val_))\r\n",
        "#    df.loc[val_, 'kfold'] = fold\r\n",
        "\r\n",
        "#df.to_csv(\"/content/drive/MyDrive/RoBERTa_files/train_fold.csv\", index=False)\r\n",
        "#test.to_csv(\"/content/drive/MyDrive/RoBERTa_files/test_fold.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19785 4947\n",
            "19785 4947\n",
            "19786 4946\n",
            "19786 4946\n",
            "19786 4946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9gYGcLNTTz"
      },
      "source": [
        "import os\r\n",
        "import string\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn import model_selection\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from transformers import *\r\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\r\n",
        "import tokenizers"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWxMIPZy5W5T",
        "outputId": "0d3688cf-4d71-41c0-90c8-950060c3dc36"
      },
      "source": [
        "# If there's a GPU available...\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    # Tell PyTorch to use the GPU.    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "# If not...\r\n",
        "else:\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7q1nawUPMqT"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgd78eqmNbzc"
      },
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\r\n",
        "class config:\r\n",
        "    TRAIN_BATCH_SIZE = 32\r\n",
        "    VALID_BATCH_SIZE = 16\r\n",
        "    EPOCHS = 3\r\n",
        "    PATH = '/content/drive/MyDrive/RoBERTa_files'\r\n",
        "    TRAINING_FILE = pd.read_csv(f\"{PATH}/train_fold.csv\")\r\n",
        "    TEST_FILE =  pd.read_csv(f\"{PATH}/test_fold.csv\")\r\n",
        "    MAX_LEN = 192\r\n",
        "    TOKENIZER = ByteLevelBPETokenizer(f\"{PATH}/vocab.json\",\r\n",
        "                                      f\"{PATH}/merges.txt\",\r\n",
        "                                      lowercase=True, add_prefix_space=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFOXQ5K2XA-l"
      },
      "source": [
        "# Processing of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-qngeJ3Xahc"
      },
      "source": [
        "def process_data(text, selected_text, sentiment, tokenizer=config.TOKENIZER, max_len=config.MAX_LEN):\r\n",
        "\r\n",
        "    text = \" \" + \" \".join(str(text).split())\r\n",
        "    selected_text = \" \" + \" \".join(str(selected_text).split())\r\n",
        "\r\n",
        "    len_st = len(selected_text) - 1\r\n",
        "    idx1 = idx2 = None\r\n",
        "    for ind in (i for i, e in enumerate(text) if e == selected_text[0]):\r\n",
        "      if text[ind: ind+len_st] == selected_text:\r\n",
        "        idx1 = ind\r\n",
        "        idx2 = ind + len_st - 1\r\n",
        "        break\r\n",
        "\r\n",
        "    char_targets = [0] * len(text)\r\n",
        "\r\n",
        "    if idx1!=None and idx2!=None:\r\n",
        "        for i in range(idx1, idx2+1):\r\n",
        "            char_targets[i] = 1\r\n",
        "    else:\r\n",
        "        char_targets = [1] * len(text)\r\n",
        "\r\n",
        "    # encoding using pretrained tokenizer\r\n",
        "    tok_text = tokenizer.encode(text)\r\n",
        "    ids_orig = tok_text.ids\r\n",
        "    offsets = tok_text.offsets\r\n",
        "\r\n",
        "    # getting indexes of tokens containing character in selected_text\r\n",
        "    target_idx = []\r\n",
        "    for i, (offset1, offset2) in enumerate(offsets):\r\n",
        "        if sum(char_targets[offset1: offset2])>0:\r\n",
        "            target_idx.append(i)\r\n",
        "\r\n",
        "    # we just need the offset indices of the start and end tokens as we are using \r\n",
        "    targets_start = target_idx[0]\r\n",
        "    targets_end = target_idx[-1]\r\n",
        "\r\n",
        "    # token ids of sentiment as present in our vocab hard coded here\r\n",
        "    sentiment_ids = {\r\n",
        "        'positive':1313,                    # tokenizer.encode('positive').ids\r\n",
        "        'negative':2430,                    # tokenizer.encode('negative').ids\r\n",
        "        'neutral':7974                     # tokenizer.encode('neutral').ids\r\n",
        "    }\r\n",
        "\r\n",
        "    # adding special tokens\r\n",
        "    input_ids = [0] + [sentiment_ids[sentiment]] + [2] + [2] + ids_orig + [2] # adding a cls token at start two SEP tokens at the end of sentiment \r\n",
        "    token_type_ids = [0, 0, 0, 0] + [0] * (len(ids_orig) + 1) # since Roberta does not need token type ids for training\r\n",
        "    attention_mask = [1] * len(token_type_ids)\r\n",
        "    offsets = [(0, 0)] * 4 + offsets # obtaining offsets of onnly tweet and adding zero for sentiments\r\n",
        "    targets_start += 4 # adding CLS sentiment and two SEP tokens\r\n",
        "    targets_end += 4\r\n",
        "\r\n",
        "    # padding\r\n",
        "    padding_len = max_len - len(input_ids)\r\n",
        "    if padding_len>0:\r\n",
        "        input_ids = input_ids + [1] * padding_len\r\n",
        "        attention_mask = attention_mask + [0] * padding_len\r\n",
        "        token_type_ids = token_type_ids + [0] * padding_len\r\n",
        "        offsets = offsets + [(0, 0)] * padding_len\r\n",
        "\r\n",
        "    return {\r\n",
        "        'ids': torch.tensor(input_ids,dtype=torch.long),\r\n",
        "        'attention_mask': torch.tensor(attention_mask,dtype=torch.long),\r\n",
        "        'token_type_ids':torch.tensor(token_type_ids,dtype=torch.long),\r\n",
        "        'targets_start': torch.tensor(targets_start,dtype=torch.long),\r\n",
        "        'targets_end':  torch.tensor(targets_end,dtype=torch.long),\r\n",
        "        'offsets': torch.tensor(offsets,dtype=torch.long),\r\n",
        "        'text': text,\r\n",
        "        'selected_text': selected_text,\r\n",
        "        'sentiment': sentiment\r\n",
        "    }"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW51NizeXrjl"
      },
      "source": [
        "class TextDataset(Dataset):\r\n",
        "    def __init__(self, text, sentiment, selected_text):\r\n",
        "        self.text = text\r\n",
        "        self.sentiment = sentiment\r\n",
        "        self.selected_text = selected_text\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.text)\r\n",
        "\r\n",
        "    def __getitem__(self, item):\r\n",
        "        # processing data\r\n",
        "        data = process_data(\r\n",
        "            self.text[item], \r\n",
        "            self.selected_text[item], \r\n",
        "            self.sentiment[item]\r\n",
        "        )\r\n",
        "        # returning tensors\r\n",
        "        return data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN2ApvivZSEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a299d3-e574-4767-ebe4-bef86e4dd4c7"
      },
      "source": [
        "#import pdb\r\n",
        "#pdb.set_trace()\r\n",
        "df = config.TRAINING_FILE.reset_index(drop=True)\r\n",
        "if __name__== \"__main__\":\r\n",
        "  dset = TextDataset(text = df.text.values,\r\n",
        "                      selected_text =df.selected_text.values,sentiment = df.sentiment.values)\r\n",
        "  print(dset[500])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ids': tensor([   0, 2430,    2,    2,   40, 2649,  127, 1928,   13,  132,  360,    2,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'targets_start': tensor(4), 'targets_end': tensor(10), 'offsets': tensor([[ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  5],\n",
            "        [ 5, 10],\n",
            "        [10, 13],\n",
            "        [13, 18],\n",
            "        [18, 22],\n",
            "        [22, 24],\n",
            "        [24, 29],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0]]), 'text': ' Will miss my baby for 2 days', 'selected_text': ' Will miss my baby for 2 days', 'sentiment': 'negative'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwNpnriG8GZv"
      },
      "source": [
        "Now weâ€™ll create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcCUgOU8PRA2"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-eadEGBNw76"
      },
      "source": [
        "class TextModel(BertPreTrainedModel):\r\n",
        "    def __init__(self,conf):\r\n",
        "        super(TextModel, self).__init__(conf)\r\n",
        "\r\n",
        "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\",config = conf)\r\n",
        "        self.drop_out = nn.Dropout(0.2)\r\n",
        "        self.l0 = nn.Linear(768 * 2, 2)\r\n",
        "        torch.nn.init.normal_(self.l0.weight, std=0.02)\r\n",
        "        # this is to initialize the weights of the matrix that would convert \r\n",
        "        # (batch_size, max_len, 2*768) to (batch_size, max_len, 1) with std=0.02 \r\n",
        "    \r\n",
        "    def forward(self, ids, attention_mask, token_type_ids):\r\n",
        "        _, _, output = self.roberta(ids,\r\n",
        "                                    attention_mask = attention_mask,\r\n",
        "                                    token_type_ids=token_type_ids).to_tuple()\r\n",
        "        \r\n",
        "        # out dim = (12, batch_size, max_len, 768)\r\n",
        "        # 12 denotes the 12 hidden layers of roberta\r\n",
        "\r\n",
        "        output = torch.cat((output[-1], output[-2]), dim=-1)\r\n",
        "        # output dim = (batch_size, max_len, 2*768)\r\n",
        "        \r\n",
        "        output = self.drop_out(output)\r\n",
        "        logits = self.l0(output)\r\n",
        "        # logits dim -> (batch_size, max_len, 2)\r\n",
        "\r\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\r\n",
        "        # start_logits and end_logits dim -> (batch_size, max_len, 1)\r\n",
        "\r\n",
        "        start_logits = start_logits.squeeze(-1)\r\n",
        "        end_logits = end_logits.squeeze(-1)\r\n",
        "        # start_logits and end_logits dim -> (batch_size, max_len)\r\n",
        "\r\n",
        "        return start_logits, end_logits"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmkzSVgdHr0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f551f8206e334cad9109367e0ace3b74",
            "36180703c37642bbb38497e863dbc4dc",
            "421a1536479f4604b365f62cce607c74",
            "59b422066ec24a0a8e2296e50b27a260",
            "926b0d72691e407d9fd59b551a409649",
            "e0443a4c4aef49e087bef65a49c7d380",
            "15b03a41dff44005b6af00232513aa99",
            "cd866624b374476eb1d5d40267adffb0",
            "1d865d0a54e04f8eb1d72af61423ea03",
            "ef9cc20681f4444aa7ab854f67c3afcc",
            "098ff8cb520e45c3935ced30603ea183",
            "399fac77b6464323a715ba1f39d58690",
            "9aa7eca8010f4c0d815a20086f7b306a",
            "042949d18d8a4e868c466466e118915e",
            "fb112d357a10455fad2d29d8bf7bef86",
            "35643256d93e41fe9e79617b9aa03368"
          ]
        },
        "outputId": "b82ee6e1-d34a-423d-b1f8-816672b692a4"
      },
      "source": [
        "conf = RobertaConfig.from_pretrained(\"roberta-base\")\r\n",
        "conf.output_hidden_states = True\r\n",
        "model = TextModel(conf)\r\n",
        "model.to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f551f8206e334cad9109367e0ace3b74",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d865d0a54e04f8eb1d72af61423ea03",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextModel(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop_out): Dropout(p=0.1, inplace=False)\n",
              "  (l0): Linear(in_features=1536, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lU4SNuJLsiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13c98b7-9d2b-476a-fad9-242ac10faaec"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\r\n",
        "params = list(model.named_parameters())\r\n",
        "print('The RoBERTa model has {:} different named parameters.\\n'.format(len(params)))\r\n",
        "print('==== Embedding Layer ====\\n')\r\n",
        "for p in params[0:5]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "print('\\n==== First Transformer ====\\n')\r\n",
        "for p in params[5:21]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "print('\\n==== Output Layer ====\\n')\r\n",
        "for p in params[-4:]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RoBERTa model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "roberta.embeddings.word_embeddings.weight               (50265, 768)\n",
            "roberta.embeddings.position_embeddings.weight             (514, 768)\n",
            "roberta.embeddings.token_type_embeddings.weight             (1, 768)\n",
            "roberta.embeddings.LayerNorm.weight                           (768,)\n",
            "roberta.embeddings.LayerNorm.bias                             (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.query.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.key.bias               (768,)\n",
            "roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.value.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
            "roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
            "roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
            "roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
            "roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n",
            "roberta.encoder.layer.0.output.dense.bias                     (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "roberta.pooler.dense.weight                               (768, 768)\n",
            "roberta.pooler.dense.bias                                     (768,)\n",
            "l0.weight                                                  (2, 1536)\n",
            "l0.bias                                                         (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZjMaPSEYTvi"
      },
      "source": [
        "# loss function. Play around with it and see what works best\r\n",
        "def loss_fn(output_start, output_end, targets_start, targets_end,device):\r\n",
        "  loss = nn.CrossEntropyLoss().to(device)\r\n",
        "  l1 = loss(output_start,targets_start)\r\n",
        "  l2 = loss(output_end,targets_end)\r\n",
        "  return l1 + l2"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fABYRm3GBTuC"
      },
      "source": [
        "import time\r\n",
        "import datetime\r\n",
        "def format_time(elapsed):\r\n",
        "    '''\r\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\r\n",
        "    '''\r\n",
        "    # Round to the nearest second.\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # Format as hh:mm:ss\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n",
        "t0 = time.time()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpBxAHPlVzDB"
      },
      "source": [
        "def train_fn(data_loader, model, optimizer, device, scheduler=None):     \r\n",
        "  model.train()\r\n",
        "  train_loss = []\r\n",
        "  for bi, batch in enumerate(data_loader):    \r\n",
        "    ids = batch['ids'].to(device, dtype=torch.long)\r\n",
        "    token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\r\n",
        "    attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\r\n",
        "    targets_start = batch['targets_start'].to(device, dtype=torch.long)\r\n",
        "    targets_end = batch['targets_end'].to(device, dtype=torch.long)\r\n",
        "    \r\n",
        "      \r\n",
        "    model.zero_grad()\r\n",
        "      \r\n",
        "    output_start,output_end = model(ids,\r\n",
        "                     attention_mask = attention_mask,\r\n",
        "                     token_type_ids = token_type_ids) \r\n",
        "      \r\n",
        "    # calculating loss\r\n",
        "    loss = loss_fn(output_start, output_end, targets_start, targets_end, device)\r\n",
        "\r\n",
        "    # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\r\n",
        "    train_loss.append(loss.item())\r\n",
        "\r\n",
        "    # Perform a backward pass to calculate the gradients.\r\n",
        "    loss.backward()\r\n",
        "    # modified based on their gradients, the learning rate, etc.\r\n",
        "    optimizer.step()\r\n",
        "    # Update the learning rate.\r\n",
        "    scheduler.step()\r\n",
        "  \r\n",
        "  avg_train_loss = np.mean(train_loss)\r\n",
        "  \r\n",
        "  print(\"\")\r\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "  print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "  \r\n",
        "  return  avg_train_loss"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI6ea68oYSPq"
      },
      "source": [
        "# jaccard function as mentioned in evaluation section of the contest\r\n",
        "def jaccard_metric(text,\r\n",
        "                   selected_text,\r\n",
        "                   sentiment,\r\n",
        "                   offsets,\r\n",
        "                   start_idx,\r\n",
        "                   end_idx): \r\n",
        "  \r\n",
        "  if end_idx < start_idx:\r\n",
        "    end_idx = start_idx\r\n",
        "    \r\n",
        "  pred  = \"\"\r\n",
        "  for idx in range(start_idx, end_idx + 1):\r\n",
        "    pred += text[offsets[idx][0]: offsets[idx][1]]\r\n",
        "    if (idx+1) < len(offsets) and offsets[idx][1] < offsets[idx+1][0]:\r\n",
        "      pred += \" \"\r\n",
        "\r\n",
        "  if len(text.split()) < 3 or sentiment=='neutral':\r\n",
        "    pred = text\r\n",
        "    \r\n",
        "  a = set(selected_text.lower().split()) \r\n",
        "  b = set(pred.lower().split())\r\n",
        "  c = a.intersection(b)\r\n",
        "  jacc = float(len(c)) / (len(a) + len(b) - len(c))\r\n",
        "\r\n",
        "  return jacc, pred"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o3V2nFgYHy9"
      },
      "source": [
        "def evaluate_fn(data_loader,model, device):  \r\n",
        "  predicted_text = []\r\n",
        "  valid_loss = []\r\n",
        "  jaccard = []\r\n",
        "  model.eval()\r\n",
        "  with torch.no_grad():\r\n",
        "    for bi, batch in enumerate(data_loader):\r\n",
        "      ids = batch[\"ids\"].to(device, dtype=torch.long)\r\n",
        "      token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\r\n",
        "      attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\r\n",
        "      targets_start = batch['targets_start'].to(device, dtype=torch.long)\r\n",
        "      targets_end = batch['targets_end'].to(device, dtype=torch.long)\r\n",
        "      offsets = batch['offsets'].cpu().numpy()\r\n",
        "      text = batch['text']\r\n",
        "      selected_text = batch['selected_text']\r\n",
        "      sentiment = batch['sentiment']\r\n",
        "\r\n",
        "      output_start, output_end = model(ids,\r\n",
        "                                       attention_mask=attention_mask,\r\n",
        "                                       token_type_ids=token_type_ids)\r\n",
        "      \r\n",
        "      loss = loss_fn(output_start, output_end, targets_start, targets_end, device)\r\n",
        "      valid_loss.append(loss.item())\r\n",
        "      output_start = torch.softmax(output_start, dim=1).cpu().detach().numpy()\r\n",
        "      output_end = torch.softmax(output_end, dim=1).cpu().detach().numpy()\r\n",
        "\r\n",
        "      for px, tweet in enumerate(text):\r\n",
        "\r\n",
        "        jacc, pred = jaccard_metric(tweet,\r\n",
        "                                    selected_text[px],\r\n",
        "                                    sentiment = sentiment[px],\r\n",
        "                                    offsets = offsets[px,:],\r\n",
        "                                    start_idx = np.argmax(output_start[px,]),\r\n",
        "                                    end_idx = np.argmax(output_end[px,]))\r\n",
        "\r\n",
        "        predicted_text.append(pred)  \r\n",
        "        jaccard.append(jacc)\r\n",
        "  print(\"  Average loss on validation data: {0:.2f}\".format(np.mean(valid_loss)))\r\n",
        "  print(\"  Average jaccard similarity on validation data: {0:.2f}\".format(np.mean(jaccard)))\r\n",
        "  print(\"  validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "  return np.mean(jaccard), predicted_text"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b8uXo0gnLYj"
      },
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/RoBERTa_files/test_fold.csv')\r\n",
        "test_dataset = TextDataset(text = test.text.values,\r\n",
        "                              selected_text = test.selected_text.values,\r\n",
        "                              sentiment = test.sentiment.values)\r\n",
        "\r\n",
        "test_dataloader = DataLoader(test_dataset,\r\n",
        "                              batch_size = 8,\r\n",
        "                              shuffle = False,\r\n",
        "                              num_workers=1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-d3nRp0mWN"
      },
      "source": [
        "def run(fold):\r\n",
        "  df = config.TRAINING_FILE\r\n",
        "  df = df.reset_index(drop=True)\r\n",
        "  train =  df[df.kfold != fold].reset_index(drop=True)\r\n",
        "  valid = df[df.kfold == fold].reset_index(drop=True)\r\n",
        "  \r\n",
        "  train_dataset = TextDataset(text = train.text.values,\r\n",
        "                              selected_text = train.selected_text.values,\r\n",
        "                              sentiment = train.sentiment.values)\r\n",
        "\r\n",
        "  train_dataloader = DataLoader(train_dataset,\r\n",
        "                              batch_size = config.TRAIN_BATCH_SIZE,\r\n",
        "                              shuffle = False,\r\n",
        "                              num_workers=4)\r\n",
        "\r\n",
        "  valid_dataset = TextDataset(text = valid.text.values,\r\n",
        "                              selected_text = valid.selected_text.values,\r\n",
        "                              sentiment = valid.sentiment.values)\r\n",
        "\r\n",
        "  valid_dataloader = DataLoader(valid_dataset,\r\n",
        "                                batch_size = config.VALID_BATCH_SIZE,\r\n",
        "                                shuffle = False,\r\n",
        "                                num_workers=1)\r\n",
        "\r\n",
        "  conf = RobertaConfig.from_pretrained(\"roberta-base\")\r\n",
        "  conf.output_hidden_states = True\r\n",
        "  model = TextModel(conf)\r\n",
        "  model.to(device)\r\n",
        "\r\n",
        "  param_optimizer = list(model.named_parameters())\r\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\r\n",
        "  optimizer_parameters = [{\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\"weight_decay\": 1e-5},\r\n",
        "                          {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\"weight_decay\": 0.0}]\r\n",
        "\r\n",
        "  num_train_steps = int(len(train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\r\n",
        "\r\n",
        "  optimizer = AdamW(optimizer_parameters, lr=2e-5)\r\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\r\n",
        "\r\n",
        "  train_loss = []\r\n",
        "  jaccards = []\r\n",
        "  best_jaccard = 0\r\n",
        "  for epoch in range(0, config.EPOCHS):\r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    # Perform one full pass over the training set.\r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch+1, config.EPOCHS))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # Measure how long the training epoch takes.\r\n",
        "    t0 = time.time()\r\n",
        "  \r\n",
        "    avg_train_loss = train_fn(train_dataloader,model,optimizer,device,scheduler)\r\n",
        "    train_loss.append(avg_train_loss)\r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "    t0 = time.time()\r\n",
        "    jacc,_ = evaluate_fn(valid_dataloader, model, device)\r\n",
        "    jaccards.append(jacc)\r\n",
        "\r\n",
        "    if jacc > best_jaccard:\r\n",
        "      best_jaccard = jacc\r\n",
        "      print('saving model')\r\n",
        "      torch.save(model.state_dict(), '/content/drive/MyDrive/RoBERTa_files/model2.pth')\r\n",
        "  \r\n",
        "  return jaccards, train_loss"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8D47foPU0B3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efee8435-8be0-4806-ebe6-a158de0272f6"
      },
      "source": [
        "print('running zero fold')\r\n",
        "jaccs_fold0, train_loss_fold0 = run(fold=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running zero fold\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:05:32\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.51\n",
            "  validation took: 0:05:49\n",
            "saving model\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:09:22\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.51\n",
            "  validation took: 0:09:39\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:13:10\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.51\n",
            "  validation took: 0:13:27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO7eJnoZHcWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1b591d-f4d0-45fb-e0ae-58e3eae58863"
      },
      "source": [
        "('prinitng jaccard similarity on test data')\r\n",
        "jaccs,preds = evaluate_fn(test_dataloader,model,device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Average loss on validation data: 10.55\n",
            "  Average jaccard similarity on validation data: 0.71\n",
            "  validation took: 0:01:59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joYY-MC5VXhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e26ac5d4-85e6-4c8a-b353-8f56285ff027"
      },
      "source": [
        "plt.plot(train_loss_fold0)\r\n",
        "plt.ylabel('Training loss on fold 1')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PgtlBbEVFgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b70bae9-aaef-4b21-9289-e7fa168b0311"
      },
      "source": [
        "print('running first fold')\r\n",
        "jaccs_fold1, train_loss_fold1 = run(fold=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running first fold\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:04:02\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:04:20\n",
            "saving model\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:07:53\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:08:11\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:11:41\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.02\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:11:59\n",
            "saving model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gA6rDYa0pIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf297781-7530-4c5d-b0b5-a9ebec315d03"
      },
      "source": [
        "('prinitng jaccard similarity on test data')\r\n",
        "jaccs,preds = evaluate_fn(test_dataloader,model,device)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Average loss on validation data: 10.66\n",
            "  Average jaccard similarity on validation data: 0.46\n",
            "  validation took: 0:17:21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC6b04InVXr0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "56913c32-e4b4-4a3f-a2e1-5e7734df3570"
      },
      "source": [
        "print('running second fold and chage the loss function to BCE with logit loss ')\r\n",
        "jaccs_fold2, train_loss_fold2 = run(fold=2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running second fold and chage the loss function to BCE with logit loss\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a2eded9503f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running second fold and chage the loss function to BCE with logit loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjaccs_fold2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_fold2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-249b727ca5bd>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# ========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-f65d5524dc01>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     14\u001b[0m     output_start,output_end = model(ids,\n\u001b[1;32m     15\u001b[0m                      \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                      token_type_ids = token_type_ids) \n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# calculating loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-5bf90003e075>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     13\u001b[0m         _, _, output = self.roberta(ids,\n\u001b[1;32m     14\u001b[0m                                     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                     token_type_ids=token_type_ids).to_tuple()\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# out dim = (12, batch_size, max_len, 768)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         )\n\u001b[1;32m    719\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 )\n\u001b[1;32m    452\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         )\n\u001b[1;32m    391\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 15.75 GiB total capacity; 14.27 GiB already allocated; 56.88 MiB free; 14.37 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4yyEF0kVX3i"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/RoBERTa_files/model2.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fujuq7wPPCXd"
      },
      "source": [
        "### refrence for code\r\n",
        "[Roberta one fold](https://www.kaggle.com/abhishek/multiprocessing-roberta-1-fold-per-core)\r\n"
      ]
    }
  ]
}