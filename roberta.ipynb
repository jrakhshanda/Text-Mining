{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roberta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOm3T1Vk03Sfx90tFuHHEAi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b980c0afbabe4c978c3b48b06ddb85e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e20816a19ff14618922b574ff668112f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a377100084de479985626caa2e7a6b07",
              "IPY_MODEL_61c75884a7a544cb8d7eb3df3837b23b"
            ]
          }
        },
        "e20816a19ff14618922b574ff668112f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a377100084de479985626caa2e7a6b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ecd3677f9834d6b9c886cf20284404e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a49b04efb6c4e98912a5d50ccb796b0"
          }
        },
        "61c75884a7a544cb8d7eb3df3837b23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_806ffabd9b034346840aeef6dd65d5fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 1.33kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c54b6153e1d4530aa37a51f9e82c73c"
          }
        },
        "8ecd3677f9834d6b9c886cf20284404e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a49b04efb6c4e98912a5d50ccb796b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "806ffabd9b034346840aeef6dd65d5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c54b6153e1d4530aa37a51f9e82c73c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a2aaa9b57454ba68da681fb339a7dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_747df3e6619f4456b5c7a6152a36086a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f90dc37eda04c4fa90e26af9b59451c",
              "IPY_MODEL_eaf2b02734a6479b81856ce072173fa5"
            ]
          }
        },
        "747df3e6619f4456b5c7a6152a36086a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f90dc37eda04c4fa90e26af9b59451c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57764fb351a94a1893ed544cc94cd385",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1015f4330ae4746a2df33d1fdd834e1"
          }
        },
        "eaf2b02734a6479b81856ce072173fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5cdc2f2620da44c2ac15f41bbe439c3f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:05&lt;00:00, 84.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a30f90236a8345f6b01e3e2b60629a2e"
          }
        },
        "57764fb351a94a1893ed544cc94cd385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1015f4330ae4746a2df33d1fdd834e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cdc2f2620da44c2ac15f41bbe439c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a30f90236a8345f6b01e3e2b60629a2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrakhshanda/Text-Mining/blob/main/roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekcMUspsNFY2",
        "outputId": "5c6ca171-2630-49fe-edf4-7be0fc40dfdf"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVGoYWYBP9gs",
        "outputId": "94d2ffa7-8ee2-4ea2-ac5f-197c66d2a3c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install tokenizers\r\n",
        "#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\r\n",
        "#!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\r\n",
        "#!export XLA_USE_BF16=1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (0.9.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDDlFXNGvhtc"
      },
      "source": [
        "#df, test = model_selection.train_test_split(df_train,test_size=0.1)\r\n",
        "#test.to_csv('/content/drive/MyDrive/BERT_files/test_fold.csv')\r\n",
        "\r\n",
        "#df[\"kfold\"] = -1\r\n",
        "#df = df.sample(frac=1).reset_index(drop=True)\r\n",
        "\r\n",
        "#kf = model_selection.StratifiedKFold(n_splits=5)\r\n",
        "\r\n",
        "#for fold, (trn_, val_) in enumerate(kf.split(X=df, y=df.sentiment.values)):\r\n",
        "#    print(len(trn_), len(val_))\r\n",
        "#    df.loc[val_, 'kfold'] = fold\r\n",
        "\r\n",
        "#df.to_csv(\"/content/drive/MyDrive/RoBERTa_files/train_fold.csv\", index=False)\r\n",
        "#test.to_csv(\"/content/drive/MyDrive/RoBERTa_files/test_fold.csv\", index=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9gYGcLNTTz"
      },
      "source": [
        "import os\r\n",
        "import string\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn import model_selection\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from transformers import *\r\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\r\n",
        "import tokenizers"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWxMIPZy5W5T",
        "outputId": "50cf22d1-988c-4ee0-df7d-4d0aefd4d2d8"
      },
      "source": [
        "# If there's a GPU available...\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    # Tell PyTorch to use the GPU.    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "# If not...\r\n",
        "else:\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7q1nawUPMqT"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgd78eqmNbzc"
      },
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\r\n",
        "class config:\r\n",
        "    TRAIN_BATCH_SIZE = 64\r\n",
        "    VALID_BATCH_SIZE = 32\r\n",
        "    EPOCHS = 3\r\n",
        "    PATH = '/content/drive/MyDrive/RoBERTa_files'\r\n",
        "    TRAINING_FILE = pd.read_csv(\"/content/drive/MyDrive/RoBERTa_files/train_folds.csv\")\r\n",
        "    TEST_FILE =  pd.read_csv(\"/content/drive/MyDrive/RoBERTa_files/test.csv\")\r\n",
        "    MAX_LEN = 192\r\n",
        "    TOKENIZER = ByteLevelBPETokenizer(f\"{PATH}/vocab.json\",\r\n",
        "                                      f\"{PATH}/merges.txt\",\r\n",
        "                                      lowercase=True, add_prefix_space=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFOXQ5K2XA-l"
      },
      "source": [
        "# Processing of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-qngeJ3Xahc"
      },
      "source": [
        "def process_data(text, selected_text, sentiment, tokenizer=config.TOKENIZER, max_len=config.MAX_LEN):\r\n",
        "\r\n",
        "    text = \" \" + \" \".join(str(text).split())\r\n",
        "    selected_text = \" \" + \" \".join(str(selected_text).split())\r\n",
        "\r\n",
        "    len_st = len(selected_text) - 1\r\n",
        "    idx1 = idx2 = None\r\n",
        "    for ind in (i for i, e in enumerate(text) if e == selected_text[0]):\r\n",
        "      if text[ind: ind+len_st] == selected_text:\r\n",
        "        idx1 = ind\r\n",
        "        idx2 = ind + len_st - 1\r\n",
        "        break\r\n",
        "\r\n",
        "    char_targets = [0] * len(text)\r\n",
        "\r\n",
        "    if idx1!=None and idx2!=None:\r\n",
        "        for i in range(idx1, idx2+1):\r\n",
        "            char_targets[i] = 1\r\n",
        "    else:\r\n",
        "        char_targets = [1] * len(text)\r\n",
        "\r\n",
        "    # encoding using pretrained tokenizer\r\n",
        "    tok_text = tokenizer.encode(text)\r\n",
        "    ids_orig = tok_text.ids\r\n",
        "    offsets = tok_text.offsets\r\n",
        "\r\n",
        "    # getting indexes of tokens containing character in selected_text\r\n",
        "    target_idx = []\r\n",
        "    for i, (offset1, offset2) in enumerate(offsets):\r\n",
        "        if sum(char_targets[offset1: offset2])>0:\r\n",
        "            target_idx.append(i)\r\n",
        "\r\n",
        "    # we just need the offset indices of the start and end tokens as we are using \r\n",
        "    targets_start = target_idx[0]\r\n",
        "    targets_end = target_idx[-1]\r\n",
        "\r\n",
        "    # token ids of sentiment as present in our vocab hard coded here\r\n",
        "    sentiment_ids = {\r\n",
        "        'positive':1313,                    # tokenizer.encode('positive').ids\r\n",
        "        'negative':2430,                    # tokenizer.encode('negative').ids\r\n",
        "        'neutral':7974                     # tokenizer.encode('neutral').ids\r\n",
        "    }\r\n",
        "\r\n",
        "    # adding special tokens\r\n",
        "    input_ids = [0] + [sentiment_ids[sentiment]] + [2] + [2] + ids_orig + [2] # adding a cls token at start two SEP tokens at the end of sentiment \r\n",
        "    token_type_ids = [0, 0, 0, 0] + [0] * (len(ids_orig) + 1) # since Roberta does not need token type ids for training\r\n",
        "    attention_mask = [1] * len(token_type_ids)\r\n",
        "    offsets = [(0, 0)] * 4 + offsets # obtaining offsets of onnly tweet and adding zero for sentiments\r\n",
        "    targets_start += 4 # adding CLS sentiment and two SEP tokens\r\n",
        "    targets_end += 4\r\n",
        "\r\n",
        "    # padding\r\n",
        "    padding_len = max_len - len(input_ids)\r\n",
        "    if padding_len>0:\r\n",
        "        input_ids = input_ids + [1] * padding_len\r\n",
        "        attention_mask = attention_mask + [0] * padding_len\r\n",
        "        token_type_ids = token_type_ids + [0] * padding_len\r\n",
        "        offsets = offsets + [(0, 0)] * padding_len\r\n",
        "\r\n",
        "    return {\r\n",
        "        'ids': torch.tensor(input_ids,dtype=torch.long),\r\n",
        "        'attention_mask': torch.tensor(attention_mask,dtype=torch.long),\r\n",
        "        'token_type_ids':torch.tensor(token_type_ids,dtype=torch.long),\r\n",
        "        'targets_start': torch.tensor(targets_start,dtype=torch.long),\r\n",
        "        'targets_end':  torch.tensor(targets_end,dtype=torch.long),\r\n",
        "        'offsets': torch.tensor(offsets,dtype=torch.long),\r\n",
        "        'text': text,\r\n",
        "        'selected_text': selected_text,\r\n",
        "        'sentiment': sentiment\r\n",
        "    }"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW51NizeXrjl"
      },
      "source": [
        "class TextDataset(Dataset):\r\n",
        "    def __init__(self, text, sentiment, selected_text):\r\n",
        "        self.text = text\r\n",
        "        self.sentiment = sentiment\r\n",
        "        self.selected_text = selected_text\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.text)\r\n",
        "\r\n",
        "    def __getitem__(self, item):\r\n",
        "        # processing data\r\n",
        "        data = process_data(\r\n",
        "            self.text[item], \r\n",
        "            self.selected_text[item], \r\n",
        "            self.sentiment[item]\r\n",
        "        )\r\n",
        "        # returning tensors\r\n",
        "        return data"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN2ApvivZSEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c202c114-1cbc-4ef3-b2e4-1a8d6206ff20"
      },
      "source": [
        "#import pdb\r\n",
        "#pdb.set_trace()\r\n",
        "df = config.TRAINING_FILE.reset_index(drop=True)\r\n",
        "if __name__== \"__main__\":\r\n",
        "  dset = TextDataset(text = df.text.values,\r\n",
        "                      selected_text =df.selected_text.values,sentiment = df.sentiment.values)\r\n",
        "  print(dset[500])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ids': tensor([    0,  1313,     2,     2,  4428,   101,    47,   351, 19925,  3974,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'targets_start': tensor(4), 'targets_end': tensor(9), 'offsets': tensor([[ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  7],\n",
            "        [ 7, 12],\n",
            "        [12, 16],\n",
            "        [16, 20],\n",
            "        [20, 30],\n",
            "        [30, 37],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0]]), 'text': ' Sounds like you won backstage passes', 'selected_text': ' won', 'sentiment': 'positive'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwNpnriG8GZv"
      },
      "source": [
        "Now we’ll create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcCUgOU8PRA2"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-eadEGBNw76"
      },
      "source": [
        "class TextModel(BertPreTrainedModel):\r\n",
        "    def __init__(self,conf):\r\n",
        "        super(TextModel, self).__init__(conf)\r\n",
        "\r\n",
        "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\",config = conf)\r\n",
        "        self.drop_out = nn.Dropout(0.2)\r\n",
        "        self.l0 = nn.Linear(768 * 2, 2)\r\n",
        "        torch.nn.init.normal_(self.l0.weight, std=0.02)\r\n",
        "        # this is to initialize the weights of the matrix that would convert \r\n",
        "        # (batch_size, max_len, 2*768) to (batch_size, max_len, 1) with std=0.02 \r\n",
        "    \r\n",
        "    def forward(self, ids, attention_mask, token_type_ids):\r\n",
        "        _, _, output = self.roberta(ids,\r\n",
        "                                    attention_mask = attention_mask,\r\n",
        "                                    token_type_ids=token_type_ids).to_tuple()\r\n",
        "        \r\n",
        "        # out dim = (12, batch_size, max_len, 768)\r\n",
        "        # 12 denotes the 12 hidden layers of roberta\r\n",
        "\r\n",
        "        output = torch.cat((output[-1], output[-2]), dim=-1)\r\n",
        "        # output dim = (batch_size, max_len, 2*768)\r\n",
        "        \r\n",
        "        output = self.drop_out(output)\r\n",
        "        logits = self.l0(output)\r\n",
        "        # logits dim -> (batch_size, max_len, 2)\r\n",
        "\r\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\r\n",
        "        # start_logits and end_logits dim -> (batch_size, max_len, 1)\r\n",
        "\r\n",
        "        start_logits = start_logits.squeeze(-1)\r\n",
        "        end_logits = end_logits.squeeze(-1)\r\n",
        "        # start_logits and end_logits dim -> (batch_size, max_len)\r\n",
        "\r\n",
        "        return start_logits, end_logits"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmkzSVgdHr0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b980c0afbabe4c978c3b48b06ddb85e8",
            "e20816a19ff14618922b574ff668112f",
            "a377100084de479985626caa2e7a6b07",
            "61c75884a7a544cb8d7eb3df3837b23b",
            "8ecd3677f9834d6b9c886cf20284404e",
            "5a49b04efb6c4e98912a5d50ccb796b0",
            "806ffabd9b034346840aeef6dd65d5fd",
            "5c54b6153e1d4530aa37a51f9e82c73c",
            "9a2aaa9b57454ba68da681fb339a7dbd",
            "747df3e6619f4456b5c7a6152a36086a",
            "7f90dc37eda04c4fa90e26af9b59451c",
            "eaf2b02734a6479b81856ce072173fa5",
            "57764fb351a94a1893ed544cc94cd385",
            "d1015f4330ae4746a2df33d1fdd834e1",
            "5cdc2f2620da44c2ac15f41bbe439c3f",
            "a30f90236a8345f6b01e3e2b60629a2e"
          ]
        },
        "outputId": "edacacea-b77d-4f4e-b976-d33f57cb35ae"
      },
      "source": [
        "conf = RobertaConfig.from_pretrained(\"roberta-base\")\r\n",
        "conf.output_hidden_states = True\r\n",
        "model = TextModel(conf)\r\n",
        "model.to(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b980c0afbabe4c978c3b48b06ddb85e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a2aaa9b57454ba68da681fb339a7dbd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextModel(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop_out): Dropout(p=0.2, inplace=False)\n",
              "  (l0): Linear(in_features=1536, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lU4SNuJLsiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835b2277-3e64-4250-e32c-fc6c9649c104"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\r\n",
        "params = list(model.named_parameters())\r\n",
        "print('The RoBERTa model has {:} different named parameters.\\n'.format(len(params)))\r\n",
        "print('==== Embedding Layer ====\\n')\r\n",
        "for p in params[0:5]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "print('\\n==== First Transformer ====\\n')\r\n",
        "for p in params[5:21]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "print('\\n==== Output Layer ====\\n')\r\n",
        "for p in params[-4:]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RoBERTa model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "roberta.embeddings.word_embeddings.weight               (50265, 768)\n",
            "roberta.embeddings.position_embeddings.weight             (514, 768)\n",
            "roberta.embeddings.token_type_embeddings.weight             (1, 768)\n",
            "roberta.embeddings.LayerNorm.weight                           (768,)\n",
            "roberta.embeddings.LayerNorm.bias                             (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.query.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.key.bias               (768,)\n",
            "roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.value.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
            "roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
            "roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
            "roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
            "roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n",
            "roberta.encoder.layer.0.output.dense.bias                     (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "roberta.pooler.dense.weight                               (768, 768)\n",
            "roberta.pooler.dense.bias                                     (768,)\n",
            "l0.weight                                                  (2, 1536)\n",
            "l0.bias                                                         (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZjMaPSEYTvi"
      },
      "source": [
        "# loss function. Play around with it and see what works best\r\n",
        "def loss_fn(output_start, output_end, targets_start, targets_end,device):\r\n",
        "  loss = nn.CrossEntropyLoss().to(device)\r\n",
        "  l1 = loss(output_start,targets_start)\r\n",
        "  l2 = loss(output_end,targets_end)\r\n",
        "  return l1 + l2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fABYRm3GBTuC"
      },
      "source": [
        "import time\r\n",
        "import datetime\r\n",
        "def format_time(elapsed):\r\n",
        "    '''\r\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\r\n",
        "    '''\r\n",
        "    # Round to the nearest second.\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # Format as hh:mm:ss\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n",
        "t0 = time.time()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpBxAHPlVzDB"
      },
      "source": [
        "def train_fn(data_loader, model, optimizer, device, scheduler=None):     \r\n",
        "  model.train()\r\n",
        "  train_loss = []\r\n",
        "  for bi, batch in enumerate(data_loader):    \r\n",
        "    ids = batch['ids'].to(device, dtype=torch.long)\r\n",
        "    token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\r\n",
        "    attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\r\n",
        "    targets_start = batch['targets_start'].to(device, dtype=torch.long)\r\n",
        "    targets_end = batch['targets_end'].to(device, dtype=torch.long)\r\n",
        "    \r\n",
        "      \r\n",
        "    model.zero_grad()\r\n",
        "      \r\n",
        "    output_start,output_end = model(ids,\r\n",
        "                     attention_mask = attention_mask,\r\n",
        "                     token_type_ids = token_type_ids) \r\n",
        "      \r\n",
        "    # calculating loss\r\n",
        "    loss = loss_fn(output_start, output_end, targets_start, targets_end, device)\r\n",
        "\r\n",
        "    # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\r\n",
        "    train_loss.append(loss.item())\r\n",
        "\r\n",
        "    # Perform a backward pass to calculate the gradients.\r\n",
        "    loss.backward()\r\n",
        "    # modified based on their gradients, the learning rate, etc.\r\n",
        "    optimizer.step()\r\n",
        "    # Update the learning rate.\r\n",
        "    scheduler.step()\r\n",
        "  \r\n",
        "  avg_train_loss = np.mean(train_loss)\r\n",
        "  \r\n",
        "  print(\"\")\r\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "  print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "  \r\n",
        "  return  avg_train_loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI6ea68oYSPq"
      },
      "source": [
        "# jaccard function as mentioned in evaluation section of the contest\r\n",
        "def jaccard_metric(text,\r\n",
        "                   selected_text,\r\n",
        "                   sentiment,\r\n",
        "                   offsets,\r\n",
        "                   start_idx,\r\n",
        "                   end_idx): \r\n",
        "  \r\n",
        "  if end_idx < start_idx:\r\n",
        "    end_idx = start_idx\r\n",
        "    \r\n",
        "  pred  = \"\"\r\n",
        "  for idx in range(start_idx, end_idx + 1):\r\n",
        "    pred += text[offsets[idx][0]: offsets[idx][1]]\r\n",
        "    if (idx+1) < len(offsets) and offsets[idx][1] < offsets[idx+1][0]:\r\n",
        "      pred += \" \"\r\n",
        "\r\n",
        "  if len(text.split()) < 3 or sentiment=='neutral':\r\n",
        "    pred = text\r\n",
        "    \r\n",
        "  a = set(selected_text.lower().split()) \r\n",
        "  b = set(pred.lower().split())\r\n",
        "  c = a.intersection(b)\r\n",
        "  jacc = float(len(c)) / (len(a) + len(b) - len(c))\r\n",
        "\r\n",
        "  return jacc, pred"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o3V2nFgYHy9"
      },
      "source": [
        "def evaluate_fn(data_loader,model, device):  \r\n",
        "  predicted_text = []\r\n",
        "  valid_loss = []\r\n",
        "  jaccard = []\r\n",
        "  model.eval()\r\n",
        "  with torch.no_grad():\r\n",
        "    for bi, batch in enumerate(data_loader):\r\n",
        "      ids = batch[\"ids\"].to(device, dtype=torch.long)\r\n",
        "      token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\r\n",
        "      attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\r\n",
        "      targets_start = batch['targets_start'].to(device, dtype=torch.long)\r\n",
        "      targets_end = batch['targets_end'].to(device, dtype=torch.long)\r\n",
        "      offsets = batch['offsets'].cpu().numpy()\r\n",
        "      text = batch['text']\r\n",
        "      selected_text = batch['selected_text']\r\n",
        "      sentiment = batch['sentiment']\r\n",
        "\r\n",
        "      output_start, output_end = model(ids,\r\n",
        "                                       attention_mask=attention_mask,\r\n",
        "                                       token_type_ids=token_type_ids)\r\n",
        "      \r\n",
        "      loss = loss_fn(output_start, output_end, targets_start, targets_end, device)\r\n",
        "      valid_loss.append(loss.item())\r\n",
        "      output_start = torch.softmax(output_start, dim=1).cpu().detach().numpy()\r\n",
        "      output_end = torch.softmax(output_end, dim=1).cpu().detach().numpy()\r\n",
        "\r\n",
        "      for px, tweet in enumerate(text):\r\n",
        "\r\n",
        "        jacc, pred = jaccard_metric(tweet,\r\n",
        "                                    selected_text[px],\r\n",
        "                                    sentiment = sentiment[px],\r\n",
        "                                    offsets = offsets[px,:],\r\n",
        "                                    start_idx = np.argmax(output_start[px,]),\r\n",
        "                                    end_idx = np.argmax(output_end[px,]))\r\n",
        "\r\n",
        "        predicted_text.append(pred)  \r\n",
        "        jaccard.append(jacc)\r\n",
        "  print(\"  Average loss on validation data: {0:.2f}\".format(np.mean(valid_loss)))\r\n",
        "  print(\"  Average jaccard similarity on validation data: {0:.2f}\".format(np.mean(jaccard)))\r\n",
        "  print(\"  validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "  return np.mean(jaccard), predicted_text"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-d3nRp0mWN"
      },
      "source": [
        "def run(fold):\r\n",
        "  df = config.TRAINING_FILE\r\n",
        "  df = df.reset_index(drop=True)\r\n",
        "  train =  df[df.kfold != fold].reset_index(drop=True)\r\n",
        "  valid = df[df.kfold == fold].reset_index(drop=True)\r\n",
        "  \r\n",
        "  train_dataset = TextDataset(text = train.text.values,\r\n",
        "                              selected_text = train.selected_text.values,\r\n",
        "                              sentiment = train.sentiment.values)\r\n",
        "\r\n",
        "  train_dataloader = DataLoader(train_dataset,\r\n",
        "                              batch_size = config.TRAIN_BATCH_SIZE,\r\n",
        "                              shuffle = False,\r\n",
        "                              num_workers=4)\r\n",
        "\r\n",
        "  valid_dataset = TextDataset(text = valid.text.values,\r\n",
        "                              selected_text = valid.selected_text.values,\r\n",
        "                              sentiment = valid.sentiment.values)\r\n",
        "\r\n",
        "  valid_dataloader = DataLoader(valid_dataset,\r\n",
        "                                batch_size = config.VALID_BATCH_SIZE,\r\n",
        "                                shuffle = False,\r\n",
        "                                num_workers=1)\r\n",
        "\r\n",
        "  conf = RobertaConfig.from_pretrained(\"roberta-base\")\r\n",
        "  conf.output_hidden_states = True\r\n",
        "  model = TextModel(conf)\r\n",
        "  model.to(device)\r\n",
        "  model = nn.DataParallel(model)\r\n",
        "\r\n",
        "  param_optimizer = list(model.named_parameters())\r\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\r\n",
        "  optimizer_parameters = [{\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\"weight_decay\": 1e-5},\r\n",
        "                          {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\"weight_decay\": 0.0001}]\r\n",
        "\r\n",
        "  num_train_steps = int(len(train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\r\n",
        "\r\n",
        "  optimizer = AdamW(optimizer_parameters, lr=2e-5)\r\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\r\n",
        "\r\n",
        "  train_loss = []\r\n",
        "  jaccards = []\r\n",
        "  best_jaccard = 0\r\n",
        "  for epoch in range(0, config.EPOCHS):\r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    # Perform one full pass over the training set.\r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch+1, config.EPOCHS))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # Measure how long the training epoch takes.\r\n",
        "    t0 = time.time()\r\n",
        "  \r\n",
        "    avg_train_loss = train_fn(train_dataloader,model,optimizer,device,scheduler)\r\n",
        "    train_loss.append(avg_train_loss)\r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "    t0 = time.time()\r\n",
        "    jacc,_ = evaluate_fn(valid_dataloader, model, device)\r\n",
        "    jaccards.append(jacc)\r\n",
        "\r\n",
        "    if jacc > best_jaccard:\r\n",
        "      best_jaccard = jacc\r\n",
        "      print('saving model')\r\n",
        "  \r\n",
        "  torch.save(model.state_dict(), '/content/drive/MyDrive/RoBERTa_files/model2.pth')\r\n",
        "\r\n",
        "  return jaccards, train_loss"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8D47foPU0B3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84bb378-9df3-4f84-8ef7-7e2bb932d3cd"
      },
      "source": [
        "print('running zero fold')\r\n",
        "jaccs_fold0, train_loss_fold0 = run(fold=0)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running zero fold\n",
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:05:36\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:05:57\n",
            "saving model\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:09:54\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:10:15\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:14:08\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:14:28\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:18:22\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:18:43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joYY-MC5VXhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "bd041ceb-6200-4e16-e4a7-cef8cf7e9e44"
      },
      "source": [
        "plt.plot(train_loss_fold0)\r\n",
        "plt.ylabel('Training loss on fold 1')\r\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yV9d3/8dcnm41AmAkCMpQRECLaOuqoihPKsNqhtv5qe1ur9+1dZ4ejw9W7ra22VTttay0gKrio2w4HCUIYMsLQJCCEvROSfH5/nCt6jBknkJPrnOT9fDyuR865Vj6XR8471/e6vtfX3B0REZFYpYRdgIiIJBcFh4iINIuCQ0REmkXBISIizaLgEBGRZkkLu4DW0KtXLx80aFDYZYiIJJXCwsIt7p5dd367CI5BgwZRUFAQdhkiIknFzN6rb76aqkREpFkUHCIi0iwKDhERaRYFh4iINIuCQ0REmkXBISIizaLgEBGRZlFwNOLF5Zv429vvh12GiEhCaRcdAA/V3wtKeH1VOccP7sGQ7M5hlyMikhB0xtGIH04ZTWZaCjc+XkRNjQa8EhGBOAeHmU0ys5VmVmxmN9Wz/BQzW2hmVWY2PWr+aWa2KGo6YGZTgmV/NLN1UcvGxav+Pl2z+N75I1mwfjuPvLE+Xr9GRCSpxC04zCwVeAA4BxgJXGJmI+us9j5wOfBo9Ex3f8Xdx7n7OOB0YB/wj6hVrq9d7u6L4nUMANMn5PCZ4dnc/fxK3t+6L56/SkQkKcTzjGMiUOzua929EngMmBy9gruvd/cioKaR/UwHnnP3UL61zYw7p44hNcW48fEiNEa7iLR38QyOAUBJ1PvSYF5zXQz8rc68H5lZkZn9zMwy69vIzK40swIzKygvLz+EX/uR/t07cMu5x/DG2q08qrusRKSdS+iL42bWDxgDzI+afTNwNHAc0AO4sb5t3f0hd8939/zs7E88Tr7ZLpmYy6eP6smdz66gbMf+w96fiEiyimdwlAG5Ue9zgnnNcRHwhLsfrJ3h7hs9ogL4A5EmsbgzM+6amkd1jXPLnCVqshKRdiuewbEAGGZmg80sg0iT09xm7uMS6jRTBWchmJkBU4ClLVBrTAb27MiNk0bw2qpyZheWttavFRFJKHELDnevAq4m0sz0LjDT3ZeZ2R1mdiGAmR1nZqXADOBBM1tWu72ZDSJyxvJanV3/1cyWAEuAXsAP43UM9bn0U4M4btAR/ODp5WzadaA1f7WISEKw9tDkkp+f7y05dOza8j2cc98/OXlYNg9fOoHIyY+ISNtiZoXunl93fkJfHE9UQ7I7879nDefFdzcxd/GGsMsREWlVCo5DdMVJQxib253b5i6jfHdF2OWIiLQaBcchSk0xfjI9j70V1dw2d1nTG4iItBEKjsMwrE8Xrv3sMJ5ZspHnlmwMuxwRkVah4DhMV54yhFH9u/K9p5ayfW9l2OWIiMSdguMwpaemcO/0sezYd5Db56nJSkTaPgVHCxjZvytXnTaUJxdt4MXlm8IuR0QkrhQcLeTq04Yyok8XvvPkEnbuP9j0BiIiSUrB0UIy0lK4d0YeW/ZU8qNnloddjohI3Cg4WlBeTneuPGUIMwtKeX3V4T3KXUQkUSk4Wti1ZwxjSHYnbp6zhD0VVWGXIyLS4hQcLSwrPZV7p+exYed+7nru3bDLERFpcQqOOJhwZA++euJg/vLm+/xnzZawyxERaVEKjjj59lkjOLJnR256fAn7KtVkJSJth4IjTjpkpHL3tDze37aPe+evDLscEZEWo+CIoxOG9OTLJxzJH/+znoL128IuR0SkRSg44uzGc46mf7cO3DC7iAMHq8MuR0TksCk44qxzZhp3TRvD2i17+dmLq8IuR0TksMU1OMxskpmtNLNiM7upnuWnmNlCM6sys+l1llWb2aJgmhs1f7CZvRXs8+9mlhHPY2gJJw/L5uLjcnn49bUsKtkRdjkiIoclbsFhZqnAA8A5wEjgEjMbWWe194HLgUfr2cV+dx8XTBdGzb8b+Jm7DwW2A1e0ePFxcMt5x9C7SxY3zF5MRZWarEQkecXzjGMiUOzua929EngMmBy9gruvd/cioCaWHZqZAacDs4NZfwKmtFzJ8dM1K50fTx3Nqk17uP/l4rDLERE5ZPEMjgFASdT70mBerLLMrMDM3jSz2nDoCexw99qOEc3dZ6hOP7oPU48dwK9eXcPSsp1hlyMickgS+eL4ke6eD3wB+LmZHdWcjc3syiB4CsrLE+eBg9+/YCRHdMzghtlFHKyO6URLRCShxDM4yoDcqPc5wbyYuHtZ8HMt8CpwLLAV6G5maU3t090fcvd8d8/Pzs5ufvVx0r1jBj+cMprlG3fxm1fXhF2OiEizxTM4FgDDgrugMoCLgblNbAOAmR1hZpnB617AicByd3fgFaD2DqzLgKdavPI4mzS6L+fn9eMXL69m1abdYZcjItIscQuO4DrE1cB84F1gprsvM7M7zOxCADM7zsxKgRnAg2ZWO2j3MUCBmS0mEhR3uXvt6Eg3AteZWTGRax6/i9cxxNPtF46iS1Y6189aTJWarEQkiVjkj/i2LT8/3wsKCsIu4xPmLt7ANX97h5vPOZqvf6ZZl3BEROLOzAqDa80fk8gXx9u8C/L6cdbIPvzfC6tYU74n7HJERGKi4AiRmfHDKaPpkJ7KDbOLqK5p+2d/IpL8FBwh6901i++fP5LC97bzp/+sD7scEZEmKTgSwNTxAzh1RDb3zF/Be1v3hl2OiEijFBwJwMy4c+oY0lNSuPHxImrUZCUiCUzBkSD6devALecdw5trt/Ho2++HXY6ISIMUHAnk4uNyOXFoT+589l1Kt+8LuxwRkXopOBKImXHX1DwcuHnOEtpDHxsRST6HFBxmdnRLFyIRuT06ctM5R/PP1VuYVVAadjkiIp9wqGcc/2jRKuRjvnT8kUwc3IMfPLOcD3YeCLscEZGPSWtogZn9oqFFQPf4lCMAKSnGPdPymHTf63zniSX89rJ8ImNYiYiEr7Ezjq8AS4HCOlMBUBn/0tq3Qb068e2zRvDSis08tWhD2OWIiHyowTMOIo9FX+ru/6m7wMxui1tF8qGvnDiYZ5Zs5LZ5yzhxaC+yu2SGXZKISKNnHNOBRfUtcPfB8SlHoqWmGPdOz2NfRTXff2pp2OWIiACNBIe7b3N3dSYI2dDeXbj2s8N4bukHPLtkY9jliIioH0cy+PopQxgzoBvfe3Ip2/bq8pKIhEvBkQTSUlO4Z3oeuw4c5PZ5y5reQEQkjhQcSeKYfl355mlDeWrRBl5YvinsckSkHWusH8c8oMFnXrj7hXGpSBp01alDeX7pB3zniSVMHNSDbh3Twy5JRNqhxs44fgL8H7AO2A88HEx7gDWx7NzMJpnZSjMrNrOb6ll+ipktNLMqM5seNX+cmb1hZsvMrMjMPh+17I9mts7MFgXTuNgONfllpKVw7/SxbN1byQ+eWR52OSLSTjV4xuHurwGY2f/VGax8npkVNLVjM0sFHgDOBEqBBWY2192jv/HeBy4Hvl1n833Ape6+2sz6A4VmNt/ddwTLr3f32U3V0BaNyenG108Zwq9eXcP5ef04dUTvsEsSkXYmlmscncxsSO0bMxsMdIphu4lAsbuvdfdK4DFgcvQK7r7e3YuAmjrzV7n76uD1BmAzkB3D72wXrjljGEN7d+bmOUvYfeBg2OWISDsTS3D8D/Cqmb1qZq8BrwD/HcN2A4CSqPelwbxmMbOJQAYfbx77UdCE9TMzq7c7tZldaWYFZlZQXl7e3F+b0LLSU7lneh6bdh3gzudWhF2OiLQzTQaHuz8PDAOuBa4BRrj7/HgXBmBm/YA/A19x99qzkpuBo4HjgB7AjfVt6+4PuXu+u+dnZ7e9k5XxA4/gipMG8+hb7/Of4i1hlyMi7UiDwWFmU2sn4DzgqGA6L5jXlDIgN+p9TjAvJmbWFXgG+I67v1k73903ekQF8AciTWLt0nVnjmBQz47cOKeIvRVVYZcjIu1EY2ccFzQynR/DvhcAw8xssJllABcDc2MpKlj/CeCRuhfBg7MQLPKc8SlEnuDbLnXISOWe6WMp2bafe+evDLscEWknGrur6iuHs2N3rzKzq4H5QCrwe3dfZmZ3AAXuPtfMjiMSEEcAF5jZ7e4+CrgIOAXoaWaXB7u83N0XAX81s2wi44IsAr5xOHUmu4mDe3DZp47kT2+s57y8fhw3qEfYJYlIG2dNjWttZt2AW4l8kQO8Btzh7jvjXFuLyc/P94KCJu8gTlp7K6o4++evk56awnPXnkxWemrYJYlIG2BmhXW6YwCx3VX1e2A3kbOAi4BdRK4tSILolJnG3dPyWLdlLz99YVXY5YhIGxdLcBzl7rcG/THWuvvtwJAmt5JWdeLQXlwyMZff/nMt77y/PexyRKQNiyU49pvZSbVvzOxEIo8gkQRz87nH0KdrFjfMLqKiqjrsckSkjYolOL4BPGBm681sPXA/8PW4ViWHpGtWOj+eOobVm/fwy5eKwy5HRNqoxvpxXBu87OzuY4E8IM/djw0eEyIJ6LQRvZk2Podfv7aGpWVJc/+CiCSRxs44am/H/SWAu+9y913xL0kO1/fOP4YenTL49qzFVFbVNL2BiEgzNBYc75rZamBE8Fyo2mmJmemMI4F175jBj6aMZsUHu/n1qzE9AV9EJGaNdQC8xMz6EunAp0GbksxZo/pywdj+3P/Kas4e3Yej+3YNuyQRaSMavTju7h+4+1h3f6/u1FoFyqG7/cJRdM1K54bZRVRVq8lKRFqGxhxvw3p0yuD2yaMoKt3Jw/9cF3Y5ItJGKDjauPPG9GPSqL787MVVFG/eE3Y5ItIGKDjaODPjjimj6JiRyg2zF1Nd0/izyUREmtJkcJjZcDN72Mz+YWYv106tUZy0jN5dsrj1gpEsfH8Hf/zP+rDLEZEk1+BdVVFmAb8BHgb0HIskNWXcAOYt3si981dwxtG9GdQrlmHjRUQ+KZamqip3/7W7v+3uhbVT3CuTFmVm/PhzY0hPSeHGx4uoUZOViByiWIJjnpldZWb9zKxH7RT3yqTF9e2WxXfPP4a31m3jr2/pjmoROTSxNFVdFvy8Pmqeo0erJ6WL8nN5umgjdz63glNH9Ca3R8ewSxKRJNPkGYe7D65nUmgkKTPjzqljMOCWJ5bQ1AiQIiJ1xXJXVbqZXWNms4PpajNLb43iJD5yjujITecczT9Xb2FmQUnY5YhIkonlGsevgQnAr4JpQjCvSWY2ycxWmlmxmd1Uz/JTzGyhmVWZ2fQ6yy4zs9XBdFnU/AnBgxaLzewXZmax1CIf98Xjj+T4wT344dPvsnGnxuUSkdjFEhzHuftl7v5yMH0FOK6pjcwsFXgAOAcYCVxiZiPrrPY+cDnwaJ1tewC3AscDE4FbzeyIYPGvga8Bw4JpUgzHIHWkpBh3T8vjYE0Nt8xRk5WIxC6W4Kg2s6Nq35jZEGLrzzERKA7GKa8EHgMmR6/g7uuDQaHqPoHvbOAFd9/m7tuBF4BJZtYP6Orub3rkm+4RYEoMtUg9BvXqxPVnH80rK8t5clFZ2OWISJKIJTiuB14xs1fN7DXgZeB/Y9huABDdgF4azItFQ9sOCF43uU8zu9LMCsysoLy8PMZf2/5c/ulBjB/YndvmLmfz7gNhlyMiSSCWu6peItIkdA3wLWCEu78S78IOl7s/5O757p6fnZ0ddjkJKzXFuGf6WPYfrOZ7Ty5Vk5WINCmmhxy6e4W7FwVTRYz7LgNyo97nBPMOZ9uy4PWh7FMaMLR3Z/7ns8OZv2wTzyzZGHY5IpLg4vl03AXAMDMbbGYZwMXA3Bi3nQ+cZWZHBBfFzwLmu/tGYJeZnRDcTXUp8FQ8im9vvnbyYPJyunHrU8vYuifWvw1EpD2KW3C4exVwNZEQeBeY6e7LzOwOM7sQwMyOM7NSYAbwoJktC7bdBvyASPgsAO4I5gFcBfwWKAbWAM/F6xjak7TUFO6dPpZdBw5y27zlYZcjIgnMmmrTNrMTgUXuvtfMvgSMB+5LpuFj8/PzvaCgIOwyksIvXlrNT19YxYNfnsDZo/qGXY6IhMjMCt09v+78WDsA7jOzsUTuplpD5DZYaYP+69SjOKZfV7775FJ27KsMuxwRSUCxPlbdifTBuN/dHwC6xLcsCUt6agr3Ts9j295KfvD0u2GXIyIJKJbg2G1mNwNfAp4xsxRAz6pqw0YP6MZ/feYoHl9YyisrN4ddjogkmFiC4/NABXCFu39A5BbYe+NalYTuW2cMZVjvztwyZwm7DhwMuxwRSSAxnXEQuRj+TzMbDowD/hbfsiRsmWmp3DM9j027DnDns2qyEpGPxBIcrwOZZjYA+AfwZeCP8SxKEsOxA4/g/508hL+9XcK/Vm8JuxwRSRCxBIe5+z5gKvArd58BjI5vWZIorjtzOIN7deKmOUXsragKuxwRSQAxBYeZfQr4IvBMM7aTNiArPdJkVbZjP/c8vyLsckQkAcQSAP8N3Aw8EfT8HgIk/EMOpeUcN6gHl31qEH964z3eXret6Q1EpE2L5em4r7n7hcADZtY5GF/jmlaoTRLIDZNGkNujAzfMXsz+yliGYxGRtiqWMcfHmNk7wDJguZkVmtmo+JcmiaRjRhp3T81j/dZ9/PSFlWGXIyIhiqWp6kHgOnc/0t0HEnnsyMPxLUsS0aeH9uILxw/kd/9ax8L3t4ddjoiEJJbg6BQ9cJO7vwp0iltFktBuPudo+nbN4obZRRw4qCYrkfYoluBYa2bfM7NBwfRdYG28C5PE1CUrnTun5VG8eQ+/eGl12OWISAhiCY6vAtnAnGDKDuZJO/WZ4dnMmJDDg6+vZUnpzrDLEZFWFstdVdvd/Rp3Hx9M17q7Grjbue+eN5KenTK4fvZiKqtqwi5HRFpRWkMLzGwe0OAoT8EtutJOdeuYzo8+N4avPVLAr14t5r8/OzzskkSklTQYHMBPWq0KSUpnjuzD5HH9uf/lYs4e1Zdj+nUNuyQRaQUNBoe7v9aahUhyuvWCUfy7eAvXz17Mk1edSFqqnkYj0tbF9V+5mU0ys5VmVmxmN9WzPNPM/h4sf8vMBgXzv2hmi6KmGjMbFyx7Ndhn7bLe8TwGaVyPThncMXk0S8t28eDrutlOpD2IW3CYWSrwAHAOMBK4xMxG1lntCmC7uw8FfgbcDeDuf3X3ce4+jshj3Ne5+6Ko7b5Yu9zdNURdyM4d049zRvflvhdXU7x5d9jliEicxfOMYyJQHDzbqhJ4jMi45dEmA38KXs8GzjAzq7POJcG2ksDumDyajpmpXD+7iOqaBu+pEJE2IJZnVc0zs7l1pj+b2bVmltXIpgOAkqj3pcG8etdx9ypgJ9Czzjqf55MjDv4haKb6Xj1BU1v3lWZWYGYF5eXlTRylHK7sLpncdsEo3nl/B3/497qwyxGROIqp5ziwh8jzqR4GdhEZTnY4cX5mlZkdD+xz96VRs7/o7mOAk4Ppy/Vt6+4PuXu+u+dnZ2fHs0wJTB7Xn88e05t7569k3Za9YZcjInESS3B82t2/4O7zgulLwHHu/k1gfCPblQG5Ue9zgnn1rmNmaUA3YGvU8oupc7bh7mXBz93Ao0SaxCQBmBk/nDKGjLQUbny8iBo1WYm0SbEER2czG1j7JnjdOXhb2ch2C4BhZjbYzDKIhMDcOuvMBS4LXk8HXnZ3D35PCnARUdc3zCzNzHoFr9OB84GlSMLo2y2L750/krfXbeMvb70XdjkiEgeNdQCs9b/Av8xsDWDAYOAqM+vERxe2P8Hdq8zsamA+kAr8PhhB8A6gwN3nAr8D/mxmxcA2IuFS6xSgxN2j7/HMBOYHoZEKvIge8Z5wZkzI4emijdz13ApOG9Gb3B4dwy5JRFqQBX/gN76SWSZwdPB2pbsfiGtVLSw/P98LCgrCLqNdKduxn7N++hrjBnbnL1ccTwP3MIhIAjOzQnfPrzs/1ttxJwCjgLHARWZ2aUsWJ23PgO4duPncY/h38VYeW1DS9AYikjRiuR33z0SeW3UScFwwfSKBROr6wsSBfGpIT370zLts2LE/7HJEpIXEcsaRD5zo7le5+7eC6Zp4FybJLyXFuGvaGKprnFueWEIszaIikvhiCY6lQN94FyJt05E9O3H92SN4dWU5cxbWvRtbRJJRLHdV9QKWm9nbQEXtTI3HIbG6/NODeHbJRm6ft4yTh/Wid9fGHjggIokuluC4Ld5FSNuWkmLcPT2Pc+/7J995cikPfXmC7rISSWJNBofG5ZCWcFR2Z647czh3PreCp4s2csHY/mGXJCKHqMFrHGb2r+DnbjPbFTXtNrNdrVeitBVXnDSYsTnduHXuMrbuqWh6AxFJSA0Gh7ufFPzs4u5do6Yu7q4xQqXZ0lJTuHfGWHYfOMitc5eFXY6IHKKYOgCaWaqZ9TezgbVTvAuTtml4ny5cc/owni7ayPNLPwi7HBE5BLF0APwWsAl4AXgmmJ6Oc13Shn3j1KMY2a8r331yKTv2NfacTBFJRLGccVwLjHD3Ue4+Jpjy4l2YtF3pqSncOyOPHfsquWPe8rDLEZFmiiU4SoiMzCfSYkb178ZVpx7FnHfKeHnFprDLEZFmiKUfx1rgVTN7ho93APxp3KqSduGbpw/l+WUfcMucpfzjuh50zUoPuyQRiUEsZxzvE7m+kQF0iZpEDktmWir3Th/L5t0H+PEz74ZdjojEKJYOgLe3RiHSPo3N7c7XThnCg6+t5by8fpw8TOPDiyS6xjoA/jz4Oc/M5tadWq9Eaev+57PDGZLdiZseX8KeiqqwyxGRJjR2xvHn4OdPWqMQab+y0lO5Z1oeMx58g7ufW8EPpowOuyQRaUSDweHuhcFPPatK4i5/UA8u//Qg/vDv9ZyX148ThvQMuyQRaUAsHQCHmdlsM1tuZmtrp1h2bmaTzGylmRWb2U31LM80s78Hy98ys0HB/EFmtt/MFgXTb6K2mWBmS4JtfmF6zGqbcf3ZIxjYoyM3Pl7E/srqsMsRkQbEclfVH4BfA1XAacAjwF+a2sjMUoEHgHOAkcAlZjayzmpXANvdfSjwM+DuqGVr3H1cMH0jav6vga8Bw4JpUgzHIEmgY0Yad0/L472t+/jJP1aGXY6INCCW4Ojg7i8B5u7vufttwHkxbDcRKHb3te5eCTwGTK6zzmTgT8Hr2cAZjZ1BmFk/oKu7v+mRcUgfAabEUIskiU8d1ZMvnTCQ3/97HYXvbQ+7HBGpRyzBUWFmKcBqM7vazD4HdI5huwFEep3XKg3m1buOu1cR6aFe27g92MzeMbPXzOzkqPVLm9gnAGZ2pZkVmFlBeXl5DOVKorjpnGPo360DN8xezIGDarISSTSxPquqI3ANMAH4EnBZPIsCNgID3f1Y4DrgUTNr1qPc3f0hd8939/zsbPUNSCadM9O4c+oY1pTv5b6XVoddjojU0WhwBNcpPu/ue9y91N2/4u7T3P3NGPZdBuRGvc8J5tW7jpmlAd2Are5e4e5b4cO7u9YAw4P1c5rYp7QBpwzP5qL8HB56fS1FpTvCLkdEojTWATDN3auBkw5x3wuAYWY22MwygIuBuh0H5/LR2ct04GV3dzPLDkILMxtC5CL4WnffCOwysxOCayGXAk8dYn2S4L5z3kh6dc7g+llFVFbVhF2OiAQaO+N4O/j5TtBb/MtmNrV2amrHwTWLq4H5wLvATHdfZmZ3mNmFwWq/A3qaWTGRJqnaW3ZPAYrMbBGRi+bfcPdtwbKrgN8CxUTORJ6L+WglqXTrkM6PPzeGlZt2c/8rxWGXIyIBi9ycVM8Cs4XuPt7M/hA12wED3N2/2hoFtoT8/HwvKCgIuww5RP/z90XMW7yBuVefxMj+GrVYpLWYWaG759ed39gZR28zuw5YCiwJfi4Lfi6NS5Ui9fj++SPp3jGD62cv5mC1mqxEwtZYcKQSue22M5HHqHeuM4m0iiM6ZfDDKaNYtmEXD70e00MLRCSOGnvI4UZ3v6PVKhFpxKTR/ThvTD/ue3E1Z47sw/A+GhJGJCyNnXHoGVCSUG6fPIpOmalcP7uI3QcOhl2OSLvVWHCc0WpViMSgV+dM7pg8msUlO5j4o5e4buYi3ly7lYZu8BCR+GjsserbGlomEpYLxvYnt0dH/r6ghHmLNzBnYRkDe3RkxoQcpk3IoX/3DmGXKNLmNXg7blui23Hbpv2V1Ty/bCMzF5TyxtqtmMFJQ3sxIz+Xs0b2ISs9NewSRZJaQ7fjKjikTSjZto9ZhaU8XlhK2Y79dM1K48Jx/bkoP5cxA7qhYVtEmk/BoeBoF2pqnP+s2cqswhKeX/oBFVU1jOjThRn5OXzu2AH07JwZdokiSUPBoeBod3buP8i8xRuYVVjK4pIdpKUYpx/dm4vyczl1RDZpqbE8HFqk/VJwKDjatVWbdjOroIQn3iljy55KenXOZNr4AczIz2Fob/UJEamPgkPBIcDB6hpeWbGZWYWlvLJiM1U1zrEDuzNjQi7nj+1H16z0sEsUSRgKDgWH1FG+u4In3yljVmEJqzbtISs9hXNG92PGhBxOGNKTlBRdUJf2TcGh4JAGuDtFpTuZWVDC3MUb2H2gipwjOjB9Qg7TxueQ26Nj2CWKhELBoeCQGBw4WM38ZR8wq6CUf6/ZgjucOLQnMybkMml0X/UNkXZFwaHgkGYq3b6PxwvLmL2whJJt++mSmcYF4/ozY0IO43K7q2+ItHkKDgWHHKKaGuetdduYVVDCs0s3cuBgDcN6dw76huSQ3UV9Q6RtUnAoOKQF7D5wkKeLNjKroISF7+8gNcU4bURvZuTncPrRvUlX3xBpQxQcCg5pYcWb9zCrsIQ5C8so311Br84ZTBk3gBn5uYzoq74hkvxCCQ4zmwTcR2Q0wd+6+111lmcCjwATgK3A5919vZmdCdwFZACVwPXu/nKwzatAP2B/sJuz3H1zY3UoOCSeqqpreG1VObMKSnnx3U1U1Thjc7oxPT+XC8f2p1sH9Q2R5NTqwWFmqcAq4EygFFgAXOLuy6PWuQrIc/dvmNnFwOfc/fNmdiywyd03mNloYL67Dwi2eRX4trvHnAQKDmktW/dU8OSiDcwqKPvo5xMAAAu2SURBVGHFB7vJTEvh7FF9mZGfw4lH9VLfEEkqDQVHY0PHHq6JQLG7rw0KeAyYDCyPWmcycFvwejZwv5mZu78Ttc4yoIOZZbp7RRzrFTlsPTtncsVJg/nqiYNYWraLWYUlPPlOGXMXb2BA9w5MGz+A6RNyGdhTfUMkecUzOAYAJVHvS4HjG1rH3avMbCfQE9gStc40YGGd0PiDmVUDjwM/9HpOm8zsSuBKgIEDBx7moYg0j5kxJqcbY3K6ccu5x/DC8k3MKizll68U84uXizlhSA9mTMjlnDF96ZgRz3+GIi0vof+PNbNRwN3AWVGzv+juZWbWhUhwfJnIdZKPcfeHgIcg0lTVCuWK1CsrPZULxvbngrH92bBjP3MWljKrsJT/nbWYW+cu4/y8fszIz2X8QPUNkeQQz+AoA3Kj3ucE8+pbp9TM0oBuRC6SY2Y5wBPApe6+pnYDdy8Lfu42s0eJNIl9IjhEElH/7h24+vRhfPO0oby9bhuzCkt5atEGHltQwlHZnZiRn8vUYwfQu2tW2KWKNCieF8fTiFwcP4NIQCwAvuDuy6LW+SYwJuri+FR3v8jMugOvAbe7+5w6++zu7lvMLB34G/Ciu/+msVp0cVwS2Z6KKp4t2siswhIWrN9OaorxmeHZXJSfw+lH9yEjTX1DJBxh3Y57LvBzIrfj/t7df2RmdwAF7j7XzLKAPwPHAtuAi919rZl9F7gZWB21u7OAvcDrQHqwzxeB69y9urE6FBySLNaW72F2YSmPLyxl064KenSq7RuSwzH9uoZdnrQz6gCo4JAkUl3jvL66nNkFpbywfBOV1TWMHtCVi4K+Id07ZoRdorQDCg4FhySp7XsreWpRGbMKS1m2YRcZqSmcOaoPF+XnctLQXqSqb4jEiYJDwSFtwLINO5lVUMpTi8rYvu8g/bplMW18DtMn5DCoV6ewy5M2RsGh4JA2pKKqmpfe3cysghJeW1VOjcPEwT2YMSGHc8f0o1NmQt9pL0lCwaHgkDbqg50HmPNOKbMKSlm3ZS+dMlI5L+gbkn/kEeobIodMwaHgkDbO3Sl8bzszC0p4pmgjeyurGdyr04dD4Pbtpr4h0jwKDgWHtCN7K6p4bukHzCwo4e1120gxOGV4NjMm5PLZkb3JTNMQuNI0BYeCQ9qp97buZXZhKbMLS9m48wDdO6YzZdwApk/IYfSAbmGXJwlMwaHgkHauusb5d/EWZhaU8I/lm6isqmFkv67MyM9hyrgBHNFJfUPk4xQcCg6RD+3cd5C5i8uYWVDKkrKdZKSm8NmRvZmRn8spw7LVN0QABYeCQ6QBKz7YxayCUp54p4xteyvp0zWTqeNzmDEhhyHZncMuT0Kk4FBwiDSqsqqGl1dE+oa8uqqc6hon/8gjmJGfw3l5/emsviHtjoJDwSESs827DvDEO2XMLChhTfleOqSncu6YflyUn8PEwT3UN6SdUHAoOESazd15p2QHswpKmbd4A3sqqjiyZ0emj89h2oQc+nfvEHaJEkcKDgWHyGHZX1nN88s2MnNBKW+s3YoZnDS0FzPyczlrZB+y0tU3pK1RcCg4RFpMybZ9zCos5fHCUsp27KdrVhrjjzyCTplpdMpIpWNGGp0z0+iYmUqnjLSP5mem0TkzanlGKp0y08hMS1HzVwJScCg4RFpcTY3zxtqtzC4sZU35HvZWVLG3opq9lVXsraiiJsavl9QUi4RIRhqdMiNh0jEjNQiX+oOnU1QofbhuZhqdMyKBlZ6qkRMPV0PBodskROSQpaQYJw7txYlDe31imbtTUVXD3ooq9lVWs6eiin2VVeypqGZfRRV7K6sjQVNZxb6Kj5bXBs++imo27DgQmResu6+y0cE+PyYjNYVO0SGTmUanjOiQqW9eJKA+nJ+Z+uGZUceMNPVvCSg4RCQuzIys9FSy0lPp2UL7rKlx9h+sDZzgZ51g2lvx0fJIUEVCqPYsaMueimDdyHoVVTUx//4O6alRZ0RRIVNP89tHZ0jR8z6+blZ6cjbRKThEJGmkpFjwRd1yX10Hq2s+DJFYguejwIos37GvkrIdkbOoPcHy6hjb6Mz4qHkuqtmt9hg/ul6U+rGzoU9eQ0r98AypNR5gGdfgMLNJwH1AKvBbd7+rzvJM4BFgArAV+Ly7rw+W3QxcAVQD17j7/Fj2KSLSHOmpKXTrkEK3Duktsr/aJrp9UU1xtSETHTh7KhoOps27D7B3y0fNc3srq4j1cnR6qn3sbOjhS/NbfHTIuAWHmaUCDwBnAqXAAjOb6+7Lo1a7Atju7kPN7GLgbuDzZjYSuBgYBfQHXjSz4cE2Te1TRCQ00U10PVrowZE1Nc6Bquo6IfPRtaCPAio4U6r4KJg6ZrT8GUg8zzgmAsXuvhbAzB4DJgPRX/KTgduC17OB+y3S4DcZeMzdK4B1ZlYc7I8Y9iki0qakpETOIjpmpEGXsKuBeN6vNgAoiXpfGsyrdx13rwJ2Aj0b2TaWfQJgZleaWYGZFZSXlx/GYYiISLQ2e6Ozuz/k7vnunp+dnR12OSIibUY8g6MMyI16nxPMq3cdM0sDuhG5SN7QtrHsU0RE4iiewbEAGGZmg80sg8jF7rl11pkLXBa8ng687JGu7HOBi80s08wGA8OAt2Pcp4iIxFHcLo67e5WZXQ3MJ3Lr7O/dfZmZ3QEUuPtc4HfAn4OL39uIBAHBejOJXPSuAr7p7tUA9e0zXscgIiKfpGdViYhIvRp6VlWbvTguIiLxoeAQEZFmaRdNVWZWDrx3iJv3Ara0YDlhaivH0laOA3QsiaqtHMvhHseR7v6J/gztIjgOh5kV1NfGl4zayrG0leMAHUuiaivHEq/jUFOViIg0i4JDRESaRcHRtIfCLqAFtZVjaSvHATqWRNVWjiUux6FrHCIi0iw64xARkWZRcIiISLMoOAJmNsnMVppZsZndVM/yTDP7e7D8LTMb1PpVNi2G47jczMrNbFEw/b8w6oyFmf3ezDab2dIGlpuZ/SI41iIzG9/aNcYihuM41cx2Rn0m32/tGmNlZrlm9oqZLTezZWZ2bT3rJPznEuNxJMXnYmZZZva2mS0OjuX2etZp2e8vd2/3E5EHJq4BhgAZwGJgZJ11rgJ+E7y+GPh72HUf4nFcDtwfdq0xHs8pwHhgaQPLzwWeAww4AXgr7JoP8ThOBZ4Ou84Yj6UfMD543QVYVc//Ywn/ucR4HEnxuQT/nTsHr9OBt4AT6qzTot9fOuOI+HCYW3evBGqHpI02GfhT8Ho2cEYwzG0iieU4koa7v07kqckNmQw84hFvAt3NrF/rVBe7GI4jabj7RndfGLzeDbzLJ0fhTPjPJcbjSArBf+c9wdv0YKp711OLfn8pOCIOZ5jbRBLr0LrTgiaE2WaWW8/yZBHzUMJJ4FNBU8NzZjYq7GJiETR3HEvkL9xoSfW5NHIckCSfi5mlmtkiYDPwgrs3+Jm0xPeXgqP9mQcMcvc84AU++itEwrOQyDOBxgK/BJ4MuZ4mmVln4HHgv919V9j1HKomjiNpPhd3r3b3cURGRZ1oZqPj+fsUHBGHM8xtImnyONx9q7tXBG9/C0xopdrioU0MJezuu2qbGtz9WSDdzHqFXFaDzCydyJftX919Tj2rJMXn0tRxJNvnAuDuO4BXgEl1FrXo95eCI+JwhrlNJE0eR5225guJtO0mq7nApcFdPCcAO919Y9hFNZeZ9a1tbzaziUT+XSbaHyVA5I4pIiN3vuvuP21gtYT/XGI5jmT5XMws28y6B687AGcCK+qs1qLfX3EbOjaZ+GEMc5tIYjyOa8zsQiJD8m4jcpdVQjKzvxG5s6WXmZUCtxK58Ie7/wZ4lsgdPMXAPuAr4VTauBiOYzrwX2ZWBewHLk7AP0pqnQh8GVgStKkD3AIMhKT6XGI5jmT5XPoBfzKzVCLhNtPdn47n95ceOSIiIs2ipioREWkWBYeIiDSLgkNERJpFwSEiIs2i4BARkWZRcIiISLMoOEREpFn+P1WRSf0VnXiAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PgtlBbEVFgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0324527a-5ac3-4df3-b665-2d4b6dd92a3d"
      },
      "source": [
        "print('running first fold')\r\n",
        "jaccs_fold1, train_loss_fold1 = run(fold=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running first fold\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:24:01\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:24:20\n",
            "saving model\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:28:00\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:28:19\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:31:58\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 0:32:17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC6b04InVXr0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b10f2e1d-7bef-4dd1-d0b9-dcda4140cd25"
      },
      "source": [
        "print('running second fold')\r\n",
        "jaccs_fold2, train_loss_fold2 = run(fold=2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running second fold\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-37:\n",
            "Process Process-38:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7feb90160940>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 47, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.6/selectors.py\", line 376, in select\n",
            "    fd_event_list = self._poll.poll(timeout)\n",
            "KeyboardInterrupt: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2e2785edf6cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running second fold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjaccs_fold2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_fold2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-6c92cf6775f9>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# ========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-f65d5524dc01>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Perform a backward pass to calculate the gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# modified based on their gradients, the learning rate, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wwBfvKnssji"
      },
      "source": [
        "print('running third fold')\r\n",
        "jaccs_fold3, train_loss_fold3 = run(fold=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av4tXHnONiql"
      },
      "source": [
        "print('running fourth fold')\r\n",
        "jaccs_fold4, train_loss_fold4 = run(fold=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3rw1_eJOWlp"
      },
      "source": [
        "jaccs = []\r\n",
        "losses = []\r\n",
        "jaccs.append(np.mean(np.mean(jaccs_fold0)))\r\n",
        "jaccs.append(np.mean(jaccs_fold1))\r\n",
        "jaccs.append(np.mean(jaccs_fold2))\r\n",
        "jaccs.append(np.mean(jaccs_fold3))\r\n",
        "jaccs.append(np.mean(jaccs_fold4))\r\n",
        "\r\n",
        "losses.append(np.mean(np.mean(train_loss_fold0)))\r\n",
        "losses.append(np.mean(train_loss_fold1))\r\n",
        "losses.append(np.mean(train_loss_fold2))\r\n",
        "losses.append(np.mean(jaccs_fold3))\r\n",
        "losses.append(np.mean(jaccs_fold4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWj3bFf3OYux"
      },
      "source": [
        "print('Jaccard similaritt and train loss average per fold')\r\n",
        "data = {'jaccard': jaccs, 'train_loss': losses}\r\n",
        "metrics = pd.DataFrame(data)\r\n",
        "metrics.to_csv('/content/drive/MyDrive/roberta_metrics.csv')\r\n",
        "metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ9nncAVOsq6"
      },
      "source": [
        "## Testing the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3ZdR-NmOrPv",
        "outputId": "0ef2719d-1b46-42d8-be6b-e5b49c16a9e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "conf = RobertaConfig.from_pretrained(\"roberta-base\")\r\n",
        "conf.output_hidden_states = True\r\n",
        "\r\n",
        "model0 = TextModel(conf)\r\n",
        "model0.to(device)\r\n",
        "model0 = nn.DataParallel(model0)\r\n",
        "model0.load_state_dict(torch.load(\"/content/drive/MyDrive/RoBERTa_files/model0.pth\"))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b8uXo0gnLYj",
        "outputId": "dd79a2a8-7162-4747-d693-3b3cb19e2a88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/RoBERTa_files/test.csv')\r\n",
        "test.insert(3,'selected_text', test.text)\r\n",
        "test_dataset = TextDataset(text = test.text.values,\r\n",
        "                              selected_text = test.selected_text.values,\r\n",
        "                              sentiment = test.sentiment.values)\r\n",
        "\r\n",
        "test_dataloader = DataLoader(test_dataset,\r\n",
        "                              batch_size = 16,\r\n",
        "                              shuffle = False,\r\n",
        "                              num_workers=1)\r\n",
        "jaccs, pred = evaluate_fn(test_dataloader,model0,device)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 1.00\n",
            "  validation took: 0:44:58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fujuq7wPPCXd"
      },
      "source": [
        "### refrence for code\r\n",
        "[Roberta one fold](https://www.kaggle.com/abhishek/multiprocessing-roberta-1-fold-per-core)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKpAEOzmFNy4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}