{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roberta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPV0dY89aQw/LA72RBVewK8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "030f359976a8444ba40b7cf356f8f7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a59db91a6719462ba44c592041e1e14b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_736b19113f7a4ba9a404a23428c15168",
              "IPY_MODEL_00ea9e33d5be42748dc5928283564944"
            ]
          }
        },
        "a59db91a6719462ba44c592041e1e14b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "736b19113f7a4ba9a404a23428c15168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2bacaeba62244ea6927a70647b70301c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e64300f72b6e4e6e87c385b7b1152c78"
          }
        },
        "00ea9e33d5be42748dc5928283564944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f1c0d770e29c48f18d72da2485c0f3c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:08&lt;00:00, 58.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b05057323564e84be7d84ac76a2972d"
          }
        },
        "2bacaeba62244ea6927a70647b70301c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e64300f72b6e4e6e87c385b7b1152c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1c0d770e29c48f18d72da2485c0f3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b05057323564e84be7d84ac76a2972d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "495cdc10849a485c8b3a5d11532ca7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_710d845a96ce43a5aa9944079717120b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce73ca5b2d114e3a96bab848c6dbe8c5",
              "IPY_MODEL_a81e5e960f08491b81d2756792d7bacc"
            ]
          }
        },
        "710d845a96ce43a5aa9944079717120b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce73ca5b2d114e3a96bab848c6dbe8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad823cedca9b43ec93655e576915f742",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e50730d07e72427892baea48ea2b643a"
          }
        },
        "a81e5e960f08491b81d2756792d7bacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_373d9abb3e2f4e7f9ffc04921b86fdea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:07&lt;00:00, 66.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_865d54499d4f460084ce1c58482ba810"
          }
        },
        "ad823cedca9b43ec93655e576915f742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e50730d07e72427892baea48ea2b643a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "373d9abb3e2f4e7f9ffc04921b86fdea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "865d54499d4f460084ce1c58482ba810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrakhshanda/Text-Mining/blob/main/roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekcMUspsNFY2",
        "outputId": "6e174358-89a4-4087-d47b-445cc48519ab"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVGoYWYBP9gs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101a2834-baf3-4888-80f2-90ada05ee3f1"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install tokenizers\r\n",
        "#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\r\n",
        "#!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\r\n",
        "#!export XLA_USE_BF16=1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=553695b3bf3228e9a32d68a1330207444f07937390b2708ba7b9c5272b39fcd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (0.9.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDDlFXNGvhtc"
      },
      "source": [
        "#df, test = model_selection.train_test_split(df_train,test_size=0.1)\r\n",
        "#test.to_csv('/content/drive/MyDrive/BERT_files/test_fold.csv')\r\n",
        "\r\n",
        "#df[\"kfold\"] = -1\r\n",
        "#df = df.sample(frac=1).reset_index(drop=True)\r\n",
        "\r\n",
        "#kf = model_selection.StratifiedKFold(n_splits=5)\r\n",
        "\r\n",
        "#for fold, (trn_, val_) in enumerate(kf.split(X=df, y=df.sentiment.values)):\r\n",
        "#    print(len(trn_), len(val_))\r\n",
        "#    df.loc[val_, 'kfold'] = fold\r\n",
        "\r\n",
        "#df.to_csv(\"/content/drive/MyDrive/RoBERTa_files/train_fold.csv\", index=False)\r\n",
        "#test.to_csv(\"/content/drive/MyDrive/RoBERTa_files/test_fold.csv\", index=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9gYGcLNTTz"
      },
      "source": [
        "import os\r\n",
        "import string\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn import model_selection\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from transformers import *\r\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\r\n",
        "import tokenizers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWxMIPZy5W5T",
        "outputId": "8540bfd0-c216-4828-f4db-1c74ad0a7ca0"
      },
      "source": [
        "# If there's a GPU available...\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    # Tell PyTorch to use the GPU.    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "# If not...\r\n",
        "else:\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7q1nawUPMqT"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgd78eqmNbzc"
      },
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\r\n",
        "class config:\r\n",
        "    TRAIN_BATCH_SIZE = 64\r\n",
        "    VALID_BATCH_SIZE = 32\r\n",
        "    EPOCHS = 3\r\n",
        "    PATH = '/content/drive/MyDrive/RoBERTa_files'\r\n",
        "    TRAINING_FILE = pd.read_csv(\"/content/drive/MyDrive/RoBERTa_files/train_folds.csv\",keep_default_na=False)\r\n",
        "    TEST_FILE =  pd.read_csv(\"/content/drive/MyDrive/RoBERTa_files/test.csv\")\r\n",
        "    MAX_LEN = 141\r\n",
        "    TOKENIZER = ByteLevelBPETokenizer(f\"{PATH}/vocab.json\",\r\n",
        "                                      f\"{PATH}/merges.txt\",\r\n",
        "                                      lowercase=True, add_prefix_space=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFOXQ5K2XA-l"
      },
      "source": [
        "# Processing of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-qngeJ3Xahc"
      },
      "source": [
        "def process_data(text, selected_text, sentiment, tokenizer=config.TOKENIZER, max_len=config.MAX_LEN):\r\n",
        "\r\n",
        "    text = \" \" + \" \".join(str(text).split())\r\n",
        "    selected_text = \" \" + \" \".join(str(selected_text).split())\r\n",
        "\r\n",
        "    len_st = len(selected_text) - 1\r\n",
        "    idx1 = idx2 = None\r\n",
        "    for ind in (i for i, e in enumerate(text) if e == selected_text[0]):\r\n",
        "      if text[ind: ind+len_st] == selected_text:\r\n",
        "        idx1 = ind\r\n",
        "        idx2 = ind + len_st - 1\r\n",
        "        break\r\n",
        "\r\n",
        "    char_targets = [0] * len(text)\r\n",
        "\r\n",
        "    if idx1!=None and idx2!=None:\r\n",
        "        for i in range(idx1, idx2+1):\r\n",
        "            char_targets[i] = 1\r\n",
        "    else:\r\n",
        "        char_targets = [1] * len(text)\r\n",
        "\r\n",
        "    # encoding using pretrained tokenizer\r\n",
        "    tok_text = tokenizer.encode(text)\r\n",
        "    ids_orig = tok_text.ids\r\n",
        "    offsets = tok_text.offsets\r\n",
        "\r\n",
        "    # getting indexes of tokens containing character in selected_text\r\n",
        "    target_idx = []\r\n",
        "    for i, (offset1, offset2) in enumerate(offsets):\r\n",
        "        if sum(char_targets[offset1: offset2])>0:\r\n",
        "            target_idx.append(i)\r\n",
        "\r\n",
        "    # we just need the offset indices of the start and end tokens as we are using \r\n",
        "    targets_start = target_idx[0]\r\n",
        "    targets_end = target_idx[-1]\r\n",
        "\r\n",
        "    # token ids of sentiment as present in our vocab hard coded here\r\n",
        "    sentiment_ids = {\r\n",
        "        'positive':1313,                    # tokenizer.encode('positive').ids\r\n",
        "        'negative':2430,                    # tokenizer.encode('negative').ids\r\n",
        "        'neutral':7974                     # tokenizer.encode('neutral').ids\r\n",
        "    }\r\n",
        "\r\n",
        "    # adding special tokens\r\n",
        "    input_ids = [0] + [sentiment_ids[sentiment]] + [2] + [2] + ids_orig + [2] # adding a cls token at start two SEP tokens at the end of sentiment \r\n",
        "    token_type_ids = [0, 0, 0, 0] + [0] * (len(ids_orig) + 1) # since Roberta does not need token type ids for training\r\n",
        "    attention_mask = [1] * len(token_type_ids)\r\n",
        "    offsets = [(0, 0)] * 4 + offsets # obtaining offsets of onnly tweet and adding zero for sentiments\r\n",
        "    targets_start += 4 # adding CLS sentiment and two SEP tokens\r\n",
        "    targets_end += 4\r\n",
        "\r\n",
        "    # padding\r\n",
        "    padding_len = max_len - len(input_ids)\r\n",
        "    if padding_len>0:\r\n",
        "        input_ids = input_ids + [1] * padding_len\r\n",
        "        attention_mask = attention_mask + [0] * padding_len\r\n",
        "        token_type_ids = token_type_ids + [0] * padding_len\r\n",
        "        offsets = offsets + [(0, 0)] * padding_len\r\n",
        "\r\n",
        "    return {\r\n",
        "        'ids': torch.tensor(input_ids,dtype=torch.long),\r\n",
        "        'attention_mask': torch.tensor(attention_mask,dtype=torch.long),\r\n",
        "        'token_type_ids':torch.tensor(token_type_ids,dtype=torch.long),\r\n",
        "        'targets_start': torch.tensor(targets_start,dtype=torch.long),\r\n",
        "        'targets_end':  torch.tensor(targets_end,dtype=torch.long),\r\n",
        "        'offsets': torch.tensor(offsets,dtype=torch.long),\r\n",
        "        'text': text,\r\n",
        "        'selected_text': selected_text,\r\n",
        "        'sentiment': sentiment\r\n",
        "    }"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW51NizeXrjl"
      },
      "source": [
        "class TextDataset(Dataset):\r\n",
        "    def __init__(self, text, sentiment, selected_text):\r\n",
        "        self.text = text\r\n",
        "        self.sentiment = sentiment\r\n",
        "        self.selected_text = selected_text\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.text)\r\n",
        "\r\n",
        "    def __getitem__(self, item):\r\n",
        "        # processing data\r\n",
        "        data = process_data(\r\n",
        "            self.text[item], \r\n",
        "            self.selected_text[item], \r\n",
        "            self.sentiment[item]\r\n",
        "        )\r\n",
        "        # returning tensors\r\n",
        "        return data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN2ApvivZSEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3e99ba-456a-4857-d1cf-58bd42d902e7"
      },
      "source": [
        "#import pdb\r\n",
        "#pdb.set_trace()\r\n",
        "df = config.TRAINING_FILE.reset_index(drop=True)\r\n",
        "if __name__== \"__main__\":\r\n",
        "  dset = TextDataset(text = df.text.values,\r\n",
        "                      selected_text =df.selected_text.values,sentiment = df.sentiment.values)\r\n",
        "  print(dset[500])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ids': tensor([    0,  7974,     2,     2,   662,   358,   134,   328, 30385,    23,\n",
            "         2054,   640, 40743,  6423,     4,   175,    73, 16593,   438,   306,\n",
            "          298,   571, 11134,  4607,  2841,  1916,  6184,   359,  1629,  1244,\n",
            "         4085, 25782,     7,  6605, 36636,  4063, 12846,   213,  1649,    24,\n",
            "           66,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'targets_start': tensor(4), 'targets_end': tensor(40), 'offsets': tensor([[  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   8],\n",
            "        [  8,  14],\n",
            "        [ 14,  15],\n",
            "        [ 15,  16],\n",
            "        [ 16,  25],\n",
            "        [ 25,  28],\n",
            "        [ 28,  33],\n",
            "        [ 33,  36],\n",
            "        [ 36,  40],\n",
            "        [ 40,  43],\n",
            "        [ 43,  44],\n",
            "        [ 44,  47],\n",
            "        [ 47,  48],\n",
            "        [ 48,  50],\n",
            "        [ 50,  51],\n",
            "        [ 51,  52],\n",
            "        [ 52,  53],\n",
            "        [ 53,  54],\n",
            "        [ 54,  58],\n",
            "        [ 58,  62],\n",
            "        [ 62,  65],\n",
            "        [ 65,  67],\n",
            "        [ 67,  75],\n",
            "        [ 75,  77],\n",
            "        [ 77,  78],\n",
            "        [ 78,  80],\n",
            "        [ 80,  85],\n",
            "        [ 85,  89],\n",
            "        [ 89,  92],\n",
            "        [ 92,  96],\n",
            "        [ 96,  99],\n",
            "        [ 99, 102],\n",
            "        [102, 104],\n",
            "        [104, 107],\n",
            "        [107, 113],\n",
            "        [113, 116],\n",
            "        [116, 120],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0]]), 'text': ' MORNING EVERY1! Giveaway at http://tinyurl.com/dhc4hg Mod Kid Emma pattern &$25 GiftCert to HipFabric!! GO check it out', 'selected_text': ' MORNING EVERY1! Giveaway at http://tinyurl.com/dhc4hg Mod Kid Emma pattern &$25 GiftCert to HipFabric!! GO check it out', 'sentiment': 'neutral'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwNpnriG8GZv"
      },
      "source": [
        "Now weâ€™ll create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcCUgOU8PRA2"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-eadEGBNw76"
      },
      "source": [
        "class TextModel(BertPreTrainedModel):\r\n",
        "    def __init__(self,conf):\r\n",
        "        super(TextModel, self).__init__(conf)\r\n",
        "\r\n",
        "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\",config = conf)\r\n",
        "        self.drop_out = nn.Dropout(0.1)\r\n",
        "        self.l0 = nn.Linear(768 * 2, 2)\r\n",
        "        torch.nn.init.normal_(self.l0.weight, std=0.02)\r\n",
        "        # this is to initialize the weights of the matrix that would convert \r\n",
        "        # (batch_size, max_len, 2*768) to (batch_size, max_len, 1) with std=0.02 \r\n",
        "    \r\n",
        "    def forward(self, ids, attention_mask, token_type_ids):\r\n",
        "        _, _, output = self.roberta(ids,\r\n",
        "                                    attention_mask = attention_mask,\r\n",
        "                                    token_type_ids=token_type_ids).to_tuple()\r\n",
        "        \r\n",
        "        # out dim = (12, batch_size, max_len, 768)\r\n",
        "        # 12 denotes the 12 hidden layers of roberta\r\n",
        "\r\n",
        "        output = torch.cat((output[-1], output[-2]), dim=-1)\r\n",
        "        # output dim = (batch_size, max_len, 2*768)\r\n",
        "        \r\n",
        "        output = self.drop_out(output)\r\n",
        "        logits = self.l0(output)\r\n",
        "        # logits dim -> (batch_size, max_len, 2)\r\n",
        "\r\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\r\n",
        "        # start_logits and end_logits dim -> (batch_size, max_len, 1)\r\n",
        "\r\n",
        "        start_logits = start_logits.squeeze(-1)\r\n",
        "        end_logits = end_logits.squeeze(-1)\r\n",
        "        # start_logits and end_logits dim -> (batch_size, max_len)\r\n",
        "\r\n",
        "        return start_logits, end_logits"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmkzSVgdHr0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "030f359976a8444ba40b7cf356f8f7ba",
            "a59db91a6719462ba44c592041e1e14b",
            "736b19113f7a4ba9a404a23428c15168",
            "00ea9e33d5be42748dc5928283564944",
            "2bacaeba62244ea6927a70647b70301c",
            "e64300f72b6e4e6e87c385b7b1152c78",
            "f1c0d770e29c48f18d72da2485c0f3c1",
            "2b05057323564e84be7d84ac76a2972d",
            "495cdc10849a485c8b3a5d11532ca7ad",
            "710d845a96ce43a5aa9944079717120b",
            "ce73ca5b2d114e3a96bab848c6dbe8c5",
            "a81e5e960f08491b81d2756792d7bacc",
            "ad823cedca9b43ec93655e576915f742",
            "e50730d07e72427892baea48ea2b643a",
            "373d9abb3e2f4e7f9ffc04921b86fdea",
            "865d54499d4f460084ce1c58482ba810"
          ]
        },
        "outputId": "3bf2dff5-afc1-4da0-f43f-0186435fb98c"
      },
      "source": [
        "conf = RobertaConfig.from_pretrained(\"roberta-base\")\r\n",
        "conf.output_hidden_states = True\r\n",
        "model = TextModel(conf)\r\n",
        "model.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "030f359976a8444ba40b7cf356f8f7ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "495cdc10849a485c8b3a5d11532ca7ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextModel(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop_out): Dropout(p=0.1, inplace=False)\n",
              "  (l0): Linear(in_features=1536, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lU4SNuJLsiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b698c3c7-6981-47d6-8225-ae64eb18e9ae"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\r\n",
        "params = list(model.named_parameters())\r\n",
        "print('The RoBERTa model has {:} different named parameters.\\n'.format(len(params)))\r\n",
        "print('==== Embedding Layer ====\\n')\r\n",
        "for p in params[0:5]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "print('\\n==== First Transformer ====\\n')\r\n",
        "for p in params[5:21]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "print('\\n==== Output Layer ====\\n')\r\n",
        "for p in params[-4:]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RoBERTa model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "roberta.embeddings.word_embeddings.weight               (50265, 768)\n",
            "roberta.embeddings.position_embeddings.weight             (514, 768)\n",
            "roberta.embeddings.token_type_embeddings.weight             (1, 768)\n",
            "roberta.embeddings.LayerNorm.weight                           (768,)\n",
            "roberta.embeddings.LayerNorm.bias                             (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.query.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.key.bias               (768,)\n",
            "roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.value.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
            "roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
            "roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
            "roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
            "roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n",
            "roberta.encoder.layer.0.output.dense.bias                     (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "roberta.pooler.dense.weight                               (768, 768)\n",
            "roberta.pooler.dense.bias                                     (768,)\n",
            "l0.weight                                                  (2, 1536)\n",
            "l0.bias                                                         (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZjMaPSEYTvi"
      },
      "source": [
        "# loss function. Play around with it and see what works best\r\n",
        "def loss_fn(output_start, output_end, targets_start, targets_end,device):\r\n",
        "  loss = nn.CrossEntropyLoss().to(device)\r\n",
        "  l1 = loss(output_start,targets_start)\r\n",
        "  l2 = loss(output_end,targets_end)\r\n",
        "  return l1 + l2"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fABYRm3GBTuC"
      },
      "source": [
        "import time\r\n",
        "import datetime\r\n",
        "def format_time(elapsed):\r\n",
        "    '''\r\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\r\n",
        "    '''\r\n",
        "    # Round to the nearest second.\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # Format as hh:mm:ss\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n",
        "t0 = time.time()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpBxAHPlVzDB"
      },
      "source": [
        "def train_fn(data_loader, model, optimizer, device, scheduler=None):     \r\n",
        "  model.train()\r\n",
        "  train_loss = []\r\n",
        "  for bi, batch in enumerate(data_loader):    \r\n",
        "    ids = batch['ids'].to(device, dtype=torch.long)\r\n",
        "    token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\r\n",
        "    attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\r\n",
        "    targets_start = batch['targets_start'].to(device, dtype=torch.long)\r\n",
        "    targets_end = batch['targets_end'].to(device, dtype=torch.long)\r\n",
        "    \r\n",
        "      \r\n",
        "    model.zero_grad()\r\n",
        "      \r\n",
        "    output_start,output_end = model(ids,\r\n",
        "                     attention_mask = attention_mask,\r\n",
        "                     token_type_ids = token_type_ids) \r\n",
        "      \r\n",
        "    # calculating loss\r\n",
        "    loss = loss_fn(output_start, output_end, targets_start, targets_end, device)\r\n",
        "\r\n",
        "    # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\r\n",
        "    train_loss.append(loss.item())\r\n",
        "\r\n",
        "    # Perform a backward pass to calculate the gradients.\r\n",
        "    loss.backward()\r\n",
        "    # modified based on their gradients, the learning rate, etc.\r\n",
        "    optimizer.step()\r\n",
        "    # Update the learning rate.\r\n",
        "    scheduler.step()\r\n",
        "  \r\n",
        "  avg_train_loss = np.mean(train_loss)\r\n",
        "  \r\n",
        "  print(\"\")\r\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "  print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "  \r\n",
        "  return  avg_train_loss"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI6ea68oYSPq"
      },
      "source": [
        "# jaccard function as mentioned in evaluation section of the contest\r\n",
        "def jaccard_metric(text,\r\n",
        "                   selected_text,\r\n",
        "                   sentiment,\r\n",
        "                   offsets,\r\n",
        "                   start_idx,\r\n",
        "                   end_idx): \r\n",
        "  \r\n",
        "  if end_idx < start_idx:\r\n",
        "    end_idx = start_idx\r\n",
        "    \r\n",
        "  pred  = \"\"\r\n",
        "  for idx in range(start_idx, end_idx + 1):\r\n",
        "    pred += text[offsets[idx][0]: offsets[idx][1]]\r\n",
        "    if (idx+1) < len(offsets) and offsets[idx][1] < offsets[idx+1][0]:\r\n",
        "      pred += \" \"\r\n",
        "\r\n",
        "  if len(text.split()) < 2 or sentiment=='neutral':\r\n",
        "    pred = text\r\n",
        "    \r\n",
        "  a = set(selected_text.lower().split()) \r\n",
        "  b = set(pred.lower().split())\r\n",
        "  c = a.intersection(b)\r\n",
        "  jacc = float(len(c)) / (len(a) + len(b) - len(c))\r\n",
        "\r\n",
        "  return jacc, pred"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o3V2nFgYHy9"
      },
      "source": [
        "def evaluate_fn(data_loader,model, device):  \r\n",
        "  predicted_text = []\r\n",
        "  jaccard = []\r\n",
        "  model.eval()\r\n",
        "  with torch.no_grad():\r\n",
        "    for bi, batch in enumerate(data_loader):\r\n",
        "      ids = batch[\"ids\"].to(device, dtype=torch.long)\r\n",
        "      token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\r\n",
        "      attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\r\n",
        "      targets_start = batch['targets_start'].to(device, dtype=torch.long)\r\n",
        "      targets_end = batch['targets_end'].to(device, dtype=torch.long)\r\n",
        "      offsets = batch['offsets'].cpu().numpy()\r\n",
        "      text = batch['text']\r\n",
        "      selected_text = batch['selected_text']\r\n",
        "      sentiment = batch['sentiment']\r\n",
        "\r\n",
        "      output_start, output_end = model(ids,\r\n",
        "                                       attention_mask=attention_mask,\r\n",
        "                                       token_type_ids=token_type_ids)\r\n",
        "      \r\n",
        "      output_start = torch.softmax(output_start, dim=1).cpu().detach().numpy()\r\n",
        "      output_end = torch.softmax(output_end, dim=1).cpu().detach().numpy()\r\n",
        "\r\n",
        "      for px, tweet in enumerate(text):\r\n",
        "\r\n",
        "        jacc, pred = jaccard_metric(tweet,\r\n",
        "                                    selected_text[px],\r\n",
        "                                    sentiment = sentiment[px],\r\n",
        "                                    offsets = offsets[px,:],\r\n",
        "                                    start_idx = np.argmax(output_start[px,]),\r\n",
        "                                    end_idx = np.argmax(output_end[px,]))\r\n",
        "\r\n",
        "        predicted_text.append(pred)  \r\n",
        "        jaccard.append(jacc)\r\n",
        "  print(\"  Average jaccard similarity on validation data: {0:.2f}\".format(np.mean(jaccard)))\r\n",
        "  print(\"  validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "  return np.mean(jaccard), predicted_text"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-d3nRp0mWN"
      },
      "source": [
        "def run(fold):\r\n",
        "  df = config.TRAINING_FILE #.sample(5000)\r\n",
        "  df = df.reset_index(drop=True)\r\n",
        "  train =  df[df.kfold != fold]\r\n",
        "  valid = df[df.kfold == fold]\r\n",
        "\r\n",
        "  train_dataset = TextDataset(text = train.text.values,\r\n",
        "                              selected_text = train.selected_text.values,\r\n",
        "                              sentiment = train.sentiment.values)\r\n",
        "\r\n",
        "  train_dataloader = DataLoader(train_dataset,\r\n",
        "                              batch_size = config.TRAIN_BATCH_SIZE,\r\n",
        "                              shuffle = False,\r\n",
        "                              num_workers=1)\r\n",
        "\r\n",
        "  valid_dataset = TextDataset(text = valid.text.values,\r\n",
        "                              selected_text = valid.selected_text.values,\r\n",
        "                              sentiment = valid.sentiment.values)\r\n",
        "\r\n",
        "  valid_dataloader = DataLoader(valid_dataset,\r\n",
        "                                batch_size = config.VALID_BATCH_SIZE,\r\n",
        "                                shuffle = False,\r\n",
        "                                num_workers=1)\r\n",
        "\r\n",
        "  conf = RobertaConfig.from_pretrained(\"roberta-base\")\r\n",
        "  conf.output_hidden_states = True\r\n",
        "  model = TextModel(conf)\r\n",
        "  model.to(device)\r\n",
        "  model = nn.DataParallel(model)\r\n",
        "\r\n",
        "  param_optimizer = list(model.named_parameters())\r\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\r\n",
        "  optimizer_parameters = [{\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\"weight_decay\": 0.01},\r\n",
        "                          {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\"weight_decay\": 0}]\r\n",
        "\r\n",
        "  num_train_steps = len(train) / config.TRAIN_BATCH_SIZE * config.EPOCHS\r\n",
        "\r\n",
        "  optimizer = AdamW(optimizer_parameters, lr = 2e-4,)\r\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\r\n",
        "\r\n",
        "  train_loss = []\r\n",
        "  jaccards = []\r\n",
        "  best_jaccard = 0\r\n",
        "  for epoch in range(0, config.EPOCHS):\r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    # Perform one full pass over the training set.\r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch+1, config.EPOCHS))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # Measure how long the training epoch takes.\r\n",
        "    t0 = time.time()\r\n",
        "  \r\n",
        "    avg_train_loss = train_fn(train_dataloader,model,optimizer,device,scheduler)\r\n",
        "    train_loss.append(avg_train_loss)\r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "    t0 = time.time()\r\n",
        "    jacc,_ = evaluate_fn(valid_dataloader, model, device)\r\n",
        "    jaccards.append(jacc)\r\n",
        "\r\n",
        "    if jacc > best_jaccard:\r\n",
        "      best_jaccard = jacc\r\n",
        "      print('saving model')\r\n",
        "  \r\n",
        "  torch.save(model.state_dict(), '/content/drive/MyDrive/RoBERTa_files/model0.pth')\r\n",
        "\r\n",
        "  return jaccards, train_loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8D47foPU0B3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "d4974b69-706e-4634-ba83-69870e4d5051"
      },
      "source": [
        "print('running zero fold')\r\n",
        "jaccs_fold0, train_loss_fold0 = run(fold=0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running zero fold\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c1c8d89ce508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running zero fold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjaccs_fold0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_fold0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-7577e1dc4823>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# ========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-f65d5524dc01>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     14\u001b[0m     output_start,output_end = model(ids,\n\u001b[1;32m     15\u001b[0m                      \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                      token_type_ids = token_type_ids) \n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# calculating loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-78e5c70a1472>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     13\u001b[0m         _, _, output = self.roberta(ids,\n\u001b[1;32m     14\u001b[0m                                     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                     token_type_ids=token_type_ids).to_tuple()\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# out dim = (12, batch_size, max_len, 768)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         )\n\u001b[1;32m    719\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 )\n\u001b[1;32m    452\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         )\n\u001b[1;32m    391\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 15.90 GiB total capacity; 14.53 GiB already allocated; 25.88 MiB free; 14.97 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joYY-MC5VXhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7cf1ea82-4ef8-4f10-8d22-a3eace60e713"
      },
      "source": [
        "plt.plot(train_loss_fold0)\r\n",
        "plt.ylabel('Training loss on fold 0')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PgtlBbEVFgW"
      },
      "source": [
        "print('running first fold')\r\n",
        "jaccs_fold1, train_loss_fold1 = run(fold=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC6b04InVXr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485c91bb-1668-4090-e7ed-f6609d21290e"
      },
      "source": [
        "print('running second fold')\r\n",
        "jaccs_fold2, train_loss_fold2 = run(fold=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running second fold\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 1:43:03\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 1:43:16\n",
            "saving model\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 1:46:38\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 1:46:50\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 1:50:11\n",
            "\n",
            "Running Validation...\n",
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 0.59\n",
            "  validation took: 1:50:23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wwBfvKnssji"
      },
      "source": [
        "print('running third fold')\r\n",
        "jaccs_fold3, train_loss_fold3 = run(fold=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av4tXHnONiql"
      },
      "source": [
        "print('running fourth fold')\r\n",
        "jaccs_fold4, train_loss_fold4 = run(fold=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soaE0F_nTaGo"
      },
      "source": [
        "print('running 5th fold')\r\n",
        "jaccs_fold5, train_loss_fold5 = run(fold=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n95pd7d5Tqh0"
      },
      "source": [
        "print('running fourth fold')\r\n",
        "jaccs_fold6, train_loss_fold6 = run(fold=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3rw1_eJOWlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d43a24e-a330-4102-fa1d-bdc266eb3f36"
      },
      "source": [
        "jaccs = []\r\n",
        "losses = []\r\n",
        "jaccs.append(np.mean(np.mean(jaccs_fold0)))\r\n",
        "jaccs.append(np.mean(jaccs_fold1))\r\n",
        "#jaccs.append(np.mean(jaccs_fold2))\r\n",
        "#jaccs.append(np.mean(jaccs_fold3))\r\n",
        "#jaccs.append(np.mean(jaccs_fold4))\r\n",
        "\r\n",
        "losses.append(np.mean(np.mean(train_loss_fold0)))\r\n",
        "losses.append(np.mean(train_loss_fold1))\r\n",
        "#losses.append(np.mean(train_loss_fold2))\r\n",
        "#losses.append(np.mean(jaccs_fold3))\r\n",
        "#losses.append(np.mean(jaccs_fold4))\r\n",
        "jaccs\r\n",
        "losses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04989576670227894, 0.04995759922196865]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWj3bFf3OYux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "14195291-9376-48ff-e583-0823cd7cc1a0"
      },
      "source": [
        "print('Jaccard similaritt and train loss average per fold')\r\n",
        "data = {'jaccard': jaccs, 'train_loss': losses}\r\n",
        "metrics = pd.DataFrame(data)\r\n",
        "metrics.to_csv('/content/drive/MyDrive/roberta_metrics.csv')\r\n",
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jaccard similaritt and train loss average per fold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jaccard</th>\n",
              "      <th>train_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.589685</td>\n",
              "      <td>0.049896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.589087</td>\n",
              "      <td>0.049958</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    jaccard  train_loss\n",
              "0  0.589685    0.049896\n",
              "1  0.589087    0.049958"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ9nncAVOsq6"
      },
      "source": [
        "## Testing the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3ZdR-NmOrPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49773dc0-ce74-4872-b255-c55470b117a3"
      },
      "source": [
        "conf = RobertaConfig.from_pretrained(\"roberta-base\")\r\n",
        "conf.output_hidden_states = True\r\n",
        "\r\n",
        "model0 = TextModel(conf)\r\n",
        "model0.to(device)\r\n",
        "model0 = nn.DataParallel(model0)\r\n",
        "model0.load_state_dict(torch.load(\"/content/drive/MyDrive/RoBERTa_files/model0.pth\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b8uXo0gnLYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e5d5131-a8c6-4984-f7c0-ec3f0936d7a9"
      },
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/RoBERTa_files/test.csv')\r\n",
        "test.insert(3,'selected_text', test.text)\r\n",
        "test_dataset = TextDataset(text = test.text.values,\r\n",
        "                              selected_text = test.selected_text.values,\r\n",
        "                              sentiment = test.sentiment.values)\r\n",
        "\r\n",
        "test_dataloader = DataLoader(test_dataset,\r\n",
        "                              batch_size = 16,\r\n",
        "                              shuffle = False,\r\n",
        "                              num_workers=1)\r\n",
        "jaccs, pred = evaluate_fn(test_dataloader,model0,device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Average loss on validation data: 0.00\n",
            "  Average jaccard similarity on validation data: 1.00\n",
            "  validation took: 0:02:30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW02UeiISnny",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9faf75d3-287b-49bc-acb9-5f109befcab5"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/submission.csv')\r\n",
        "submission.selected_text = pred\r\n",
        "submission.sample(40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>f0ef04109b</td>\n",
              "      <td>about to go to sleep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2564</th>\n",
              "      <td>d528912ba9</td>\n",
              "      <td>: nice to see you on twitter!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>49e9fe8b96</td>\n",
              "      <td>i want to go to singapore but my mother seems...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>8c08631422</td>\n",
              "      <td>On the phone to mum http://tinyurl.com/otdn9u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1798</th>\n",
              "      <td>198854f289</td>\n",
              "      <td>cannot relaxing because she have to practice ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3376</th>\n",
              "      <td>9e734c1ed3</td>\n",
              "      <td>I`ll put your name on the list</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2386</th>\n",
              "      <td>d276268ebf</td>\n",
              "      <td>Uh-oh...it`s becoming grey again out here. I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>b357b9e7d2</td>\n",
              "      <td>school. 39 days !!! so exited. Amazing premier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3432</th>\n",
              "      <td>d3b70656cd</td>\n",
              "      <td>_marie:my heart goes out to you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>1e41208494</td>\n",
              "      <td>alas no, it`s just a normal night monday is q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2162</th>\n",
              "      <td>27d0c01bc2</td>\n",
              "      <td>I REEEALLY wish I could be there haven`t been...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2538</th>\n",
              "      <td>6dc1aa9db8</td>\n",
              "      <td>hey Gerardo! (late response) that day i was t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2534</th>\n",
              "      <td>4c2cb5387a</td>\n",
              "      <td>god i cant even catch public transport. swine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2506</th>\n",
              "      <td>d8c30b8a27</td>\n",
              "      <td>_carter The video is set to private</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>c002c2eddd</td>\n",
              "      <td>Watching One Fine Day while eating my cereal....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2459</th>\n",
              "      <td>c2645bfd2f</td>\n",
              "      <td>ano pa bang aasahan ko sa iyo? you never fail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1646</th>\n",
              "      <td>b6262b919a</td>\n",
              "      <td>Wow, my bed is SO comfy &amp; my nap has been muc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1723</th>\n",
              "      <td>3ec9a1578c</td>\n",
              "      <td>Spilled chocolate milk in my car</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1790</th>\n",
              "      <td>10c841e57b</td>\n",
              "      <td>anyone got an FFE account? if so.. add me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>25510fbf89</td>\n",
              "      <td>I have the Job this is a nice day it can not ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>97e53162ff</td>\n",
              "      <td>dear oh dear.....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>772ba56ce6</td>\n",
              "      <td>Morning all! Have a GREAT DAY! Off to school ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3128</th>\n",
              "      <td>c29116d111</td>\n",
              "      <td>happy Star Wars day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1244</th>\n",
              "      <td>ec00ec25c7</td>\n",
              "      <td>has dislocated her knee *bad/painful times* g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>47f11efc72</td>\n",
              "      <td>this creepy guy when I was walking the dog I`...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1279</th>\n",
              "      <td>7013b54ea6</td>\n",
              "      <td>_ Heading off to Poole around 4ish, has some ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3200</th>\n",
              "      <td>88040d7737</td>\n",
              "      <td>thanks to follow. have a nice rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>77de10258b</td>\n",
              "      <td>Remmber time crisis ? Try it on the #iPhone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2184</th>\n",
              "      <td>3775f77081</td>\n",
              "      <td>having my dinner. eating bangus. it`s a fish.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1674</th>\n",
              "      <td>e6c2edcb0b</td>\n",
              "      <td>back from melly`s party... i had fun... i`m s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>a11da2d3bf</td>\n",
              "      <td>Playin City of Villains, wishin my buddies we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2446</th>\n",
              "      <td>b1caa80c14</td>\n",
              "      <td>Just finished watching Star Trek in IMAX. . ....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1109</th>\n",
              "      <td>a9bc0bc35d</td>\n",
              "      <td>i agree with the whole Hollie thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>1872e32e07</td>\n",
              "      <td>I feel like I`m on alott of drugs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1549</th>\n",
              "      <td>bc3032341b</td>\n",
              "      <td>i`m sad...i`ll miss you grandma angie.. you w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>598603422e</td>\n",
              "      <td>Shoot. Only 12 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1452</th>\n",
              "      <td>e0f9a074cf</td>\n",
              "      <td>Now I like #startrek. Personal feels that #St...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2221</th>\n",
              "      <td>4d21d7611c</td>\n",
              "      <td>He`s an amazing jockey! Saw that Clydesdale c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2144</th>\n",
              "      <td>8e3b60deaa</td>\n",
              "      <td>No problem. At least look on the floor. We wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>8429087609</td>\n",
              "      <td>Wango tango!!! Good night all</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          textID                                      selected_text\n",
              "23    f0ef04109b                               about to go to sleep\n",
              "2564  d528912ba9                      : nice to see you on twitter!\n",
              "371   49e9fe8b96   i want to go to singapore but my mother seems...\n",
              "695   8c08631422      On the phone to mum http://tinyurl.com/otdn9u\n",
              "1798  198854f289   cannot relaxing because she have to practice ...\n",
              "3376  9e734c1ed3                     I`ll put your name on the list\n",
              "2386  d276268ebf   Uh-oh...it`s becoming grey again out here. I ...\n",
              "310   b357b9e7d2     school. 39 days !!! so exited. Amazing premier\n",
              "3432  d3b70656cd                    _marie:my heart goes out to you\n",
              "857   1e41208494   alas no, it`s just a normal night monday is q...\n",
              "2162  27d0c01bc2   I REEEALLY wish I could be there haven`t been...\n",
              "2538  6dc1aa9db8   hey Gerardo! (late response) that day i was t...\n",
              "2534  4c2cb5387a   god i cant even catch public transport. swine...\n",
              "2506  d8c30b8a27                _carter The video is set to private\n",
              "1466  c002c2eddd   Watching One Fine Day while eating my cereal....\n",
              "2459  c2645bfd2f   ano pa bang aasahan ko sa iyo? you never fail...\n",
              "1646  b6262b919a   Wow, my bed is SO comfy & my nap has been muc...\n",
              "1723  3ec9a1578c                   Spilled chocolate milk in my car\n",
              "1790  10c841e57b          anyone got an FFE account? if so.. add me\n",
              "136   25510fbf89   I have the Job this is a nice day it can not ...\n",
              "401   97e53162ff                                  dear oh dear.....\n",
              "286   772ba56ce6   Morning all! Have a GREAT DAY! Off to school ...\n",
              "3128  c29116d111                                happy Star Wars day\n",
              "1244  ec00ec25c7   has dislocated her knee *bad/painful times* g...\n",
              "418   47f11efc72   this creepy guy when I was walking the dog I`...\n",
              "1279  7013b54ea6   _ Heading off to Poole around 4ish, has some ...\n",
              "3200  88040d7737                 thanks to follow. have a nice rest\n",
              "2486  77de10258b        Remmber time crisis ? Try it on the #iPhone\n",
              "2184  3775f77081      having my dinner. eating bangus. it`s a fish.\n",
              "1674  e6c2edcb0b   back from melly`s party... i had fun... i`m s...\n",
              "120   a11da2d3bf   Playin City of Villains, wishin my buddies we...\n",
              "2446  b1caa80c14   Just finished watching Star Trek in IMAX. . ....\n",
              "1109  a9bc0bc35d                i agree with the whole Hollie thing\n",
              "2995  1872e32e07                  I feel like I`m on alott of drugs\n",
              "1549  bc3032341b   i`m sad...i`ll miss you grandma angie.. you w...\n",
              "744   598603422e                               Shoot. Only 12 miles\n",
              "1452  e0f9a074cf   Now I like #startrek. Personal feels that #St...\n",
              "2221  4d21d7611c   He`s an amazing jockey! Saw that Clydesdale c...\n",
              "2144  8e3b60deaa   No problem. At least look on the floor. We wo...\n",
              "815   8429087609                      Wango tango!!! Good night all"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdCkFxbiTDld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "782a57ad-4dca-4237-d940-0ec83a3da7af"
      },
      "source": [
        "from google.colab import files\r\n",
        "submission.to_csv('submission.csv') \r\n",
        "files.download('submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2f91992e-1697-4b92-873a-c21f91948b97\", \"submission.csv\", 300697)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fujuq7wPPCXd"
      },
      "source": [
        "### refrence for code\r\n",
        "[Roberta one fold](https://www.kaggle.com/abhishek/multiprocessing-roberta-1-fold-per-core)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKpAEOzmFNy4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}